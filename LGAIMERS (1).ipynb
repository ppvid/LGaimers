{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TVAQx5VKuhcM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tEbTprqhulbt"},"outputs":[],"source":["import os\n","import random\n","import glob\n","import re\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LhNo65hruqQk"},"outputs":[],"source":["def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"W1_0YDOCutB4"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/LGaimers/해커톤/train/train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cWces1s_uv0I"},"outputs":[],"source":["# '영업장명'과 '메뉴명' 분리\n","df[['영업장명', '메뉴명']] = df['영업장명_메뉴명'].str.split('_', n=1, expand=True)\n","df['영업일자'] = pd.to_datetime(df['영업일자'])  # 문자열 → datetime 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QqaVTU-9u05r"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-01-01 00:00:00 2024-06-15 00:00:00\n"]}],"source":["print(df['영업일자'].min(), df['영업일자'].max())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zYJLzhtAwmg8"},"outputs":[],"source":["zero_sales_dict = {}\n","\n","# 메뉴별 0판매 구간 탐지\n","for menu, group in df.groupby('영업장명_메뉴명'):\n","    group = group.sort_values('영업일자').reset_index(drop=True)\n","    zero_sales = group[group['매출수량'] == 0].copy()\n","\n","    if zero_sales.empty:\n","        continue\n","\n","    zero_sales['날짜차이'] = zero_sales['영업일자'].diff().dt.days.fillna(1)\n","    group_id = (zero_sales['날짜차이'] != 1).cumsum()\n","\n","    result_list = []\n","    for _, sub in zero_sales.groupby(group_id):\n","        dates = sub['영업일자'].dt.date.tolist()\n","        if len(dates) == 1:\n","            result_list.append(f\"({dates[0]})\")\n","        else:\n","            result_list.append(f\"({dates[0]}, {dates[-1]})\")\n","    zero_sales_dict[menu] = result_list"]},{"cell_type":"markdown","metadata":{"id":"bRwBiH-sw73C"},"source":["is_zero_sales_period가 1이면 일주일 이상 판매 중단 기간"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1DNQyo_ww4uW"},"outputs":[],"source":["n = 7  # 판매 중단으로 간주할 최소 연속일 수\n","\n","df['is_zero_sales_period'] = 0  # 초기화\n","\n","for menu, periods in zero_sales_dict.items():\n","    for period in periods:\n","        dates = period.strip(\"()\").split(\", \")\n","        if len(dates) == 1:\n","            continue  # 단일 날짜는 제외\n","        else:\n","            d1 = pd.to_datetime(dates[0])\n","            d2 = pd.to_datetime(dates[1])\n","            duration = (d2 - d1).days + 1\n","\n","            if duration \u003e= n:\n","                df.loc[\n","                    (df['영업장명_메뉴명'] == menu) \u0026\n","                    (df['영업일자'].between(d1, d2)),\n","                    'is_zero_sales_period'\n","                ] = 1"]},{"cell_type":"markdown","metadata":{"id":"jhuG2nzxXzcW"},"source":["영업장별 4일 이상 매출 없는 기간 정기적 휴무일 지정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IvEUYkVSWS4C"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def find_store_zero_runs(df: pd.DataFrame,\n","                         date_col: str = '영업일자',\n","                         store_col: str = '영업장명',\n","                         sales_col: str = '매출수량',\n","                         min_run: int = 7,\n","                         treat_missing_as_zero: bool = True) -\u003e pd.DataFrame:\n","    \"\"\"\n","    영업장별로 (모든 메뉴 합계 기준) 매출수량==0 이 min_run일 이상 연속인 기간을 반환.\n","    반환 컬럼: [영업장명, start, end, run_length]\n","\n","    treat_missing_as_zero:\n","      True  -\u003e 원본에 없는 날짜(결측 일자)를 0으로 간주(리샘플링 후 0 채움)\n","      False -\u003e 원본에 있는 날짜만 사용(연속성은 원본 일자 기준)\n","    \"\"\"\n","    df = df.copy()\n","    df[date_col] = pd.to_datetime(df[date_col])\n","\n","    # 1) 영업장×날짜별 총 매출(모든 메뉴 합계)\n","    daily = (df.groupby([store_col, date_col], as_index=False)[sales_col]\n","               .sum()\n","               .rename(columns={sales_col: 'store_sales'}))\n","\n","    results = []\n","\n","    for store, g in daily.groupby(store_col, sort=False):\n","        g = g.sort_values(date_col)\n","\n","        if treat_missing_as_zero:\n","            # 영업장별 전체 날짜 인덱스로 리샘플링 → 결측일 0으로 채움\n","            full_idx = pd.date_range(g[date_col].min(), g[date_col].max(), freq='D')\n","            s = (g.set_index(date_col)['store_sales']\n","                   .reindex(full_idx)\n","                   .fillna(0.0))\n","            s.index.name = date_col\n","        else:\n","            # 원본에 존재하는 날짜만 사용(날짜 간격이 띄엄띄엄일 수 있음)\n","            s = g.set_index(date_col)['store_sales'].copy()\n","\n","        # 2) 0/비0 플래그\n","        z = (s == 0).astype(int)\n","\n","        if z.sum() == 0:\n","            continue  # 0이 한 번도 없으면 스킵\n","\n","        # 3) 연속 구간(run) 구분: 값이 바뀔 때마다 run_id 증가\n","        run_id = (z.diff().fillna(z.iloc[0]) != 0).cumsum()\n","\n","        # 4) run별 요약\n","        tmp = (\n","            pd.DataFrame({'flag_zero': z, 'run_id': run_id})\n","            .groupby('run_id', group_keys=False)\n","            .apply(lambda d: pd.Series({\n","                'flag_zero': d['flag_zero'].iloc[0],\n","                'start':     d.index.min(),\n","                'end':       d.index.max(),\n","                'run_length': len(d)\n","            }))\n","        )\n","\n","        # 5) 0인 구간 + 길이 필터\n","        zero_runs = tmp[(tmp['flag_zero'] == 1) \u0026 (tmp['run_length'] \u003e= min_run)]\n","        if zero_runs.empty:\n","            continue\n","\n","        # 6) 결과 정리\n","        for _, row in zero_runs.iterrows():\n","            results.append({\n","                store_col: store,\n","                'start':   row['start'],\n","                'end':     row['end'],\n","                'run_length': int(row['run_length']),\n","            })\n","\n","    out = pd.DataFrame(results).sort_values([store_col, 'start']).reset_index(drop=True)\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CnWfxzbdWaxX"},"outputs":[],"source":["def print_zero_runs_by_store(zero_runs_df, store_col='영업장명'):\n","    \"\"\"\n","    find_store_zero_runs() 결과를 영업장별로 보기 좋게 출력하는 함수.\n","    \"\"\"\n","    stores = zero_runs_df[store_col].unique()\n","    for store in stores:\n","        print(f\"\\n=== {store} ===\")\n","        runs = zero_runs_df[zero_runs_df[store_col] == store]\n","        if runs.empty:\n","            print(\"  (연속 0 구간 없음)\")\n","        else:\n","            for _, row in runs.iterrows():\n","                start_str = row['start'].strftime('%Y-%m-%d')\n","                end_str = row['end'].strftime('%Y-%m-%d')\n","                print(f\"  {start_str} ~ {end_str} ({row['run_length']}일)\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"collapsed":true,"id":"DuGJWGEWWc_I"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== 느티나무 셀프BBQ ===\n","  2023-03-01 ~ 2023-03-09 (9일)\n","  2024-03-03 ~ 2024-03-13 (11일)\n","\n","=== 담하 ===\n","  2023-03-02 ~ 2023-03-09 (8일)\n","  2024-03-04 ~ 2024-03-12 (9일)\n","\n","=== 라그로타 ===\n","  2023-03-02 ~ 2023-03-09 (8일)\n","  2024-03-04 ~ 2024-03-12 (9일)\n","\n","=== 미라시아 ===\n","  2023-03-02 ~ 2023-03-09 (8일)\n","  2024-03-04 ~ 2024-03-12 (9일)\n","\n","=== 연회장 ===\n","  2023-03-01 ~ 2023-03-09 (9일)\n","  2024-03-04 ~ 2024-03-13 (10일)\n","\n","=== 카페테리아 ===\n","  2023-03-02 ~ 2023-03-09 (8일)\n","  2024-03-04 ~ 2024-03-13 (10일)\n","\n","=== 포레스트릿 ===\n","  2023-03-02 ~ 2023-03-11 (10일)\n","  2023-03-13 ~ 2023-03-31 (19일)\n","  2023-04-03 ~ 2023-04-06 (4일)\n","  2023-04-10 ~ 2023-04-13 (4일)\n","  2023-04-17 ~ 2023-04-20 (4일)\n","  2023-08-28 ~ 2023-09-01 (5일)\n","  2023-09-04 ~ 2023-09-07 (4일)\n","  2023-09-11 ~ 2023-09-15 (5일)\n","  2023-09-18 ~ 2023-09-22 (5일)\n","  2023-11-27 ~ 2023-12-05 (9일)\n","  2024-03-04 ~ 2024-03-26 (23일)\n","  2024-04-29 ~ 2024-05-02 (4일)\n","  2024-05-20 ~ 2024-05-23 (4일)\n","  2024-05-27 ~ 2024-05-31 (5일)\n","  2024-06-10 ~ 2024-06-13 (4일)\n","\n","=== 화담숲주막 ===\n","  2023-01-01 ~ 2023-03-30 (89일)\n","  2023-11-27 ~ 2024-03-28 (123일)\n","\n","=== 화담숲카페 ===\n","  2023-01-01 ~ 2023-03-30 (89일)\n","  2023-11-27 ~ 2024-03-28 (123일)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-3391356828.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n"]}],"source":["zero_periods = find_store_zero_runs(\n","    df,  # 원본 데이터프레임\n","    date_col='영업일자',\n","    store_col='영업장명',\n","    sales_col='매출수량',\n","    min_run=4,\n","    treat_missing_as_zero=True\n",")\n","\n","print_zero_runs_by_store(zero_periods)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pEFJtUd4YFxJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-303728899.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# --- 1) 영업장별 \"연속 0(\u003e=min_run일)\" 구간 캘린더 생성 ---\n","def _find_store_zero_runs_calendar(df: pd.DataFrame,\n","                                   date_col='영업일자',\n","                                   store_col='영업장명',\n","                                   sales_col='매출수량',\n","                                   min_run=7,\n","                                   treat_missing_as_zero=True) -\u003e pd.DataFrame:\n","    \"\"\"\n","    반환: [영업장명, ds, 휴무일] (연속 0 구간의 모든 날짜에 휴무일=1)\n","    \"\"\"\n","    df = df.copy()\n","    df[date_col] = pd.to_datetime(df[date_col])\n","\n","    # 영업장×날짜 총매출(모든 메뉴 합)\n","    daily = (df.groupby([store_col, date_col], as_index=False)[sales_col]\n","               .sum()\n","               .rename(columns={sales_col: 'store_sales'}))\n","\n","    rows = []\n","    for store, g in daily.groupby(store_col, sort=False):\n","        g = g.sort_values(date_col)\n","\n","        # 일 단위 인덱스 확보\n","        if treat_missing_as_zero:\n","            full_idx = pd.date_range(g[date_col].min(), g[date_col].max(), freq='D')\n","            s = (g.set_index(date_col)['store_sales']\n","                   .reindex(full_idx)\n","                   .fillna(0.0))\n","            s.index.name = date_col\n","        else:\n","            s = g.set_index(date_col)['store_sales'].copy()\n","\n","        z = (s == 0).astype(int)\n","        if z.sum() == 0:\n","            continue\n","\n","        # run 분할\n","        run_id = (z.diff().fillna(z.iloc[0]) != 0).cumsum()\n","        tmp = (\n","            pd.DataFrame({'flag_zero': z, 'run_id': run_id})\n","            .groupby('run_id', group_keys=False)\n","            .apply(lambda d: pd.Series({\n","                'flag_zero': d['flag_zero'].iloc[0],\n","                'start':     d.index.min(),\n","                'end':       d.index.max(),\n","                'length':    len(d)\n","            }))\n","        )\n","\n","        # 0구간 + 길이 조건\n","        tmp = tmp[(tmp['flag_zero'] == 1) \u0026 (tmp['length'] \u003e= min_run)]\n","        if tmp.empty:\n","            continue\n","\n","        # 날짜 캘린더로 확장\n","        for _, r in tmp.iterrows():\n","            days = pd.date_range(r['start'], r['end'], freq='D')\n","            rows.append(pd.DataFrame({\n","                store_col: store,\n","                'ds': days,\n","                '휴무일': 1\n","            }))\n","\n","    if rows:\n","        off_cal = pd.concat(rows, ignore_index=True).drop_duplicates([store_col, 'ds'])\n","    else:\n","        off_cal = pd.DataFrame(columns=[store_col, 'ds', '휴무일'])\n","    return off_cal\n","\n","\n","# --- 2) 기존 휴무일 삭제 후, 새 규칙으로 생성 ---\n","def rebuild_offdays(df: pd.DataFrame,\n","                    date_col='영업일자',\n","                    store_col='영업장명',\n","                    menu_col='메뉴명',\n","                    sales_col='매출수량',\n","                    min_run=7,\n","                    treat_missing_as_zero=True,\n","                    ) -\u003e pd.DataFrame:\n","    \"\"\"\n","    기존 df의 휴무일 컬럼을 제거하고, 연속0(\u003e=min_run) + 특정 매장 월요일 규칙으로 새로 생성.\n","    반환: 휴무일(0/1)이 새로 생성된 df\n","    \"\"\"\n","    out = df.copy()\n","    out[date_col] = pd.to_datetime(out[date_col])\n","\n","    # 0) 기존 휴무일 컬럼 제거\n","    if '휴무일' in out.columns:\n","        out = out.drop(columns=['휴무일'])\n","\n","    # 1) 연속 0 구간 캘린더 생성\n","    off_cal = _find_store_zero_runs_calendar(out, date_col, store_col, sales_col,\n","                                             min_run=min_run,\n","                                             treat_missing_as_zero=treat_missing_as_zero)\n","\n","    # 2) 기본 0으로 초기화 후, 캘린더 병합으로 1 세팅\n","    out['휴무일'] = 0\n","    if not off_cal.empty:\n","        off_cal = off_cal.copy()\n","        off_cal['ds'] = pd.to_datetime(off_cal['ds'])\n","        out = out.merge(off_cal[[store_col, 'ds', '휴무일']].rename(columns={'휴무일':'휴무일_from_zero'}),\n","                        how='left', left_on=[store_col, date_col], right_on=[store_col, 'ds'])\n","        out['휴무일'] = out['휴무일_from_zero'].fillna(0).astype(int)\n","        out.drop(columns=['ds','휴무일_from_zero'], inplace=True)\n","\n","    # 4) 최종 정리: int8로 다운캐스팅(선택)\n","    out['휴무일'] = out['휴무일'].astype('int8')\n","    return out\n","\n","\n","# === 실행 예시 ===\n","# df = ... (원본)\n","df = rebuild_offdays(\n","    df,\n","    date_col='영업일자',\n","    store_col='영업장명',\n","    menu_col='메뉴명',\n","    sales_col='매출수량',\n","    min_run=4,\n","    treat_missing_as_zero=True,   # 결측 일자도 0으로 간주하여 보수적으로 탐지\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"shivast3YwKf"},"outputs":[{"name":"stdout","output_type":"stream","text":["📊 요일별 매출 0(휴무일 아님) 카운트\n","weekday_name\n","월    159\n","화     12\n","수      6\n","목      9\n","금      3\n","토      0\n","일     26\n","Name: count, dtype: int64\n","\n","=== 느티나무 셀프BBQ ===\n","weekday_name\n","월    15\n","화     2\n","Name: count, dtype: int64\n","\n","=== 라그로타 ===\n","weekday_name\n","월    51\n","화     2\n","Name: count, dtype: int64\n","\n","=== 연회장 ===\n","weekday_name\n","수     2\n","월     4\n","일    25\n","화     2\n","Name: count, dtype: int64\n","\n","=== 포레스트릿 ===\n","weekday_name\n","금     3\n","목     7\n","수     4\n","월    21\n","일     1\n","화     6\n","Name: count, dtype: int64\n","\n","=== 화담숲주막 ===\n","weekday_name\n","목     1\n","월    34\n","Name: count, dtype: int64\n","\n","=== 화담숲카페 ===\n","weekday_name\n","목     1\n","월    34\n","Name: count, dtype: int64\n"]}],"source":["def count_weekdays_for_non_offday_zero_sales(df, date_col='영업일자', store_col='영업장명',\n","                                             sales_col='매출수량', offday_col='휴무일'):\n","    \"\"\"\n","    휴무일이 아닌데 매출 0인 날짜의 요일 분포를 카운트\n","    \"\"\"\n","    df = df.copy()\n","    df[date_col] = pd.to_datetime(df[date_col])\n","\n","    # 1) 영업장 × 날짜 총매출\n","    daily_sales = (\n","        df.groupby([store_col, date_col], as_index=False)[sales_col]\n","          .sum()\n","          .rename(columns={sales_col: 'store_sales'})\n","    )\n","\n","    # 2) 휴무일 정보 병합\n","    if offday_col in df.columns:\n","        daily_sales = daily_sales.merge(\n","            df[[store_col, date_col, offday_col]].drop_duplicates(),\n","            on=[store_col, date_col],\n","            how='left'\n","        )\n","    else:\n","        daily_sales[offday_col] = 0\n","\n","    # 3) 조건 필터\n","    target = daily_sales[\n","        (daily_sales[offday_col] == 0) \u0026\n","        (daily_sales['store_sales'] == 0)\n","    ].copy()\n","\n","    # 4) 요일 컬럼 추가 (0=월, 6=일)\n","    target['weekday'] = target[date_col].dt.weekday\n","\n","    # 5) 요일 이름 매핑\n","    weekday_map = {0: '월', 1: '화', 2: '수', 3: '목', 4: '금', 5: '토', 6: '일'}\n","    target['weekday_name'] = target['weekday'].map(weekday_map)\n","\n","    # 6) 요일 카운트\n","    weekday_counts = target['weekday_name'].value_counts().reindex(weekday_map.values(), fill_value=0)\n","\n","    return target, weekday_counts\n","\n","\n","# === 실행 예시 ===\n","target_df, weekday_counts = count_weekdays_for_non_offday_zero_sales(df)\n","\n","print(\"📊 요일별 매출 0(휴무일 아님) 카운트\")\n","print(weekday_counts)\n","\n","# 필요하면 영업장별 상세 출력\n","for store, group in target_df.groupby('영업장명'):\n","    print(f\"\\n=== {store} ===\")\n","    print(group['weekday_name'].value_counts().sort_index())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lz00khSjd4S9"},"outputs":[{"name":"stdout","output_type":"stream","text":["=== 업장별·월별 0매출 요일 카운트 (휴무일 제외) ===\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"pivot_all\",\n  \"rows\": 74,\n  \"fields\": [\n    {\n      \"column\": \"\\uc6d4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubaa9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uae08\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud1a0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"pivot_all"},"text/html":["\n","  \u003cdiv id=\"df-ea2fb9cf-f7ac-4410-953c-8a2a6ccde571\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eweekday_name\u003c/th\u003e\n","      \u003cth\u003e월\u003c/th\u003e\n","      \u003cth\u003e화\u003c/th\u003e\n","      \u003cth\u003e수\u003c/th\u003e\n","      \u003cth\u003e목\u003c/th\u003e\n","      \u003cth\u003e금\u003c/th\u003e\n","      \u003cth\u003e토\u003c/th\u003e\n","      \u003cth\u003e일\u003c/th\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e영업장명\u003c/th\u003e\n","      \u003cth\u003emonth\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth rowspan=\"5\" valign=\"top\"\u003e느티나무 셀프BBQ\u003c/th\u003e\n","      \u003cth\u003e2023-03\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2023-04\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2023-07\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2023-09\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2023-10\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth rowspan=\"5\" valign=\"top\"\u003e화담숲카페\u003c/th\u003e\n","      \u003cth\u003e2023-10\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2023-11\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2024-04\u003c/th\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2024-05\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2024-06\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e74 rows × 7 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea2fb9cf-f7ac-4410-953c-8a2a6ccde571')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-ea2fb9cf-f7ac-4410-953c-8a2a6ccde571 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ea2fb9cf-f7ac-4410-953c-8a2a6ccde571');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","    \u003cdiv id=\"df-19482349-3087-4591-8b2d-1430e05cb159\"\u003e\n","      \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-19482349-3087-4591-8b2d-1430e05cb159')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","      \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() =\u003e {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-19482349-3087-4591-8b2d-1430e05cb159 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","\n","  \u003cdiv id=\"id_e72106fb-04d8-4dcf-bff0-91d4c7992ca8\"\u003e\n","    \u003cstyle\u003e\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    \u003c/style\u003e\n","    \u003cbutton class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot_all')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","    \u003cscript\u003e\n","      (() =\u003e {\n","      const buttonEl =\n","        document.querySelector('#id_e72106fb-04d8-4dcf-bff0-91d4c7992ca8 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () =\u003e {\n","        google.colab.notebook.generateWithVariable('pivot_all');\n","      }\n","      })();\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["weekday_name        월  화  수  목  금  토  일\n","영업장명       month                       \n","느티나무 셀프BBQ 2023-03  1  1  0  0  0  0  0\n","           2023-04  1  0  0  0  0  0  0\n","           2023-07  2  0  0  0  0  0  0\n","           2023-09  4  0  0  0  0  0  0\n","           2023-10  1  0  0  0  0  0  0\n","...                .. .. .. .. .. .. ..\n","화담숲카페      2023-10  1  0  0  0  0  0  0\n","           2023-11  1  0  0  0  0  0  0\n","           2024-04  5  0  0  0  0  0  0\n","           2024-05  3  0  0  0  0  0  0\n","           2024-06  2  0  0  0  0  0  0\n","\n","[74 rows x 7 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","\n","def count_zero_sales_by_store_month_weekday_excluding_offdays(\n","    df: pd.DataFrame,\n","    date_col: str = '영업일자',\n","    store_col: str = '영업장명',\n","    sales_col: str = '매출수량',\n","    offday_col: str = '휴무일',\n","    month_format: str = '%Y-%m'\n","):\n","    \"\"\"\n","    휴무일 제외 후, 업장별·월별 '매출수량=0'인 날짜의 요일 카운트를 반환합니다.\n","    \"\"\"\n","    df = df.copy()\n","    df[date_col] = pd.to_datetime(df[date_col])\n","\n","    # 1) 영업장×날짜 총매출 (모든 메뉴 합)\n","    daily_sales = (\n","        df.groupby([store_col, date_col], as_index=False)[sales_col]\n","          .sum()\n","          .rename(columns={sales_col: 'store_sales'})\n","    )\n","\n","    # 2) 휴무일 정보 병합 \u0026 제외\n","    if offday_col in df.columns:\n","        offday_info = (\n","            df[[store_col, date_col, offday_col]]\n","            .drop_duplicates([store_col, date_col])\n","        )\n","        daily_sales = daily_sales.merge(offday_info, on=[store_col, date_col], how='left')\n","        daily_sales = daily_sales[daily_sales[offday_col].fillna(0).astype(int) == 0]\n","\n","    # 3) 0매출 날짜만 필터\n","    zero_sales = daily_sales[daily_sales['store_sales'] == 0].copy()\n","\n","    # 4) 요일 / 월 파생\n","    zero_sales['weekday'] = zero_sales[date_col].dt.weekday  # 월=0 … 일=6\n","    weekday_map = {0:'월', 1:'화', 2:'수', 3:'목', 4:'금', 5:'토', 6:'일'}\n","    zero_sales['weekday_name'] = zero_sales['weekday'].map(weekday_map)\n","    zero_sales['month'] = zero_sales[date_col].dt.strftime(month_format)\n","\n","    # 5) Long 형태 집계\n","    counts_long = (\n","        zero_sales.groupby([store_col, 'month', 'weekday_name'], as_index=False)\n","                  .size()\n","                  .rename(columns={'size':'zero_days'})\n","    )\n","\n","    # 6) Pivot 형태\n","    counts_pivot = (\n","        counts_long.pivot_table(index=[store_col, 'month'],\n","                                columns='weekday_name',\n","                                values='zero_days',\n","                                aggfunc='sum',\n","                                fill_value=0)\n","                    .reindex(columns=['월','화','수','목','금','토','일'], fill_value=0)\n","                    .sort_index()\n","    )\n","\n","    return counts_pivot, counts_long\n","\n","\n","# 사용 예시\n","pivot_all, long_all = count_zero_sales_by_store_month_weekday_excluding_offdays(df)\n","\n","print(\"=== 업장별·월별 0매출 요일 카운트 (휴무일 제외) ===\")\n","display(pivot_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EIIrbBPCfOIz"},"outputs":[{"name":"stdout","output_type":"stream","text":["=== 휴무일 지정 계획 ===\n","느티나무 셀프BBQ (2023-09): 월\n","라그로타 (2023-02): 월\n","라그로타 (2023-03): 월\n","라그로타 (2023-04): 월\n","라그로타 (2023-05): 월\n","라그로타 (2023-06): 월\n","라그로타 (2023-07): 월\n","라그로타 (2023-08): 월\n","라그로타 (2023-09): 월\n","라그로타 (2023-11): 월\n","라그로타 (2024-04): 월\n","라그로타 (2024-05): 월\n","연회장 (2023-03): 일\n","연회장 (2023-04): 일\n","포레스트릿 (2023-05): 월\n","포레스트릿 (2023-10): 월\n","포레스트릿 (2023-11): 월\n","포레스트릿 (2024-04): 월\n","화담숲주막 (2023-04): 월\n","화담숲주막 (2023-05): 월\n","화담숲주막 (2023-06): 월\n","화담숲주막 (2023-07): 월\n","화담숲주막 (2023-08): 월\n","화담숲주막 (2023-09): 월\n","화담숲주막 (2024-04): 월\n","화담숲주막 (2024-05): 월\n","화담숲카페 (2023-04): 월\n","화담숲카페 (2023-05): 월\n","화담숲카페 (2023-06): 월\n","화담숲카페 (2023-07): 월\n","화담숲카페 (2023-08): 월\n","화담숲카페 (2023-09): 월\n","화담숲카페 (2024-04): 월\n","화담숲카페 (2024-05): 월\n"]}],"source":["def assign_offdays_by_zero_sales(pivot_table, threshold=3):\n","    \"\"\"\n","    pivot_table: count_zero_sales_by_store_month_weekday_excluding_offdays()의 pivot_all 결과\n","    threshold: 해당 요일이 이 횟수 이상이면 휴무일로 지정\n","    \"\"\"\n","    offday_records = []\n","\n","    for (store, month), row in pivot_table.iterrows():\n","        # 3회 이상인 요일 추출\n","        offdays = [day for day, cnt in row.items() if cnt \u003e= threshold]\n","        if offdays:\n","            offday_records.append({\n","                '영업장명': store,\n","                '월': month,\n","                '휴무요일': offdays\n","            })\n","\n","    return pd.DataFrame(offday_records)\n","\n","\n","# 사용 예시\n","pivot_all, _ = count_zero_sales_by_store_month_weekday_excluding_offdays(df)\n","offday_plan_df = assign_offdays_by_zero_sales(pivot_all, threshold=3)\n","\n","print(\"=== 휴무일 지정 계획 ===\")\n","for _, row in offday_plan_df.iterrows():\n","    print(f\"{row['영업장명']} ({row['월']}): {', '.join(row['휴무요일'])}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FUNBIaBU3LC6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def add_custom_offday_only(\n","    df: pd.DataFrame,\n","    date_col: str = '영업일자',\n","    store_col: str = '영업장명',\n","    offday_col: str = '휴무일',      # 0=영업, 1=휴무\n","    out_col: str = 'custom_offday'\n",") -\u003e pd.DataFrame:\n","    \"\"\"\n","    기존 휴무일(offday_col)==0(영업일)에서만 규칙을 적용해 custom_offday=1을 부여합니다.\n","    규칙:\n","      - 포레스트릿: 4,5,9,10,11월 \u0026 월요일(weekday=0)\n","      - 연회장: 일요일(weekday=6)\n","      - 화담숲주막/화담숲카페/라그로타/느티나무 셀프BBQ: 월요일(weekday=0)\n","    \"\"\"\n","    if offday_col not in df.columns:\n","        raise KeyError(f\"'{offday_col}' 컬럼이 필요합니다. (0=영업, 1=휴무)\")\n","\n","    out = df.copy()\n","    out[date_col] = pd.to_datetime(out[date_col])\n","\n","    # --- 휴무일 컬럼 정규화 (bool/문자열/숫자 모두 처리) ---\n","    off = out[offday_col]\n","    if off.dtype == bool or set(off.dropna().unique()) \u003c= {True, False}:\n","        off = off.astype(int)\n","    elif off.dtype == 'O':  # 'holiday'/'non-holiday' 등 문자열\n","        off = (off.replace({'holiday': 1, 'non-holiday': 0})\n","                 .pipe(pd.to_numeric, errors='coerce')\n","                 .fillna(0).astype(int))\n","    else:\n","        off = pd.to_numeric(off, errors='coerce').fillna(0).astype(int)\n","    # 영업 중(휴무 아님) 조건\n","    is_op = (off == 0).values\n","\n","    # --- 파생 ---\n","    out['weekday'] = out[date_col].dt.weekday  # 월=0 … 일=6\n","    out['month']   = out[date_col].dt.month\n","\n","    # --- 기본 0 ---\n","    custom = np.zeros(len(out), dtype=np.int8)\n","\n","    # 1) 포레스트릿: 4,5,9,10,11월 \u0026 월요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '포레스트릿') \u0026\n","        (out['month'].isin([4,5,9,10,11])) \u0026\n","        (out['weekday'] == 0) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    # 2) 연회장: 일요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '연회장') \u0026\n","        (out['weekday'] == 6) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    # 3) 화담숲주막: 월요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '화담숲주막') \u0026\n","        (out['weekday'] == 0) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    # 4) 화담숲카페: 월요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '화담숲카페') \u0026\n","        (out['weekday'] == 0) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    # 5) 라그로타: 월요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '라그로타') \u0026\n","        (out['weekday'] == 0) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    # 6) 느티나무 셀프BBQ: 월요일 \u0026 영업 중\n","    mask = (\n","        (out[store_col] == '느티나무 셀프BBQ') \u0026\n","        (out['weekday'] == 0) \u0026 is_op\n","    )\n","    custom = np.where(mask, 1, custom)\n","\n","    out[out_col] = custom.astype('int8')\n","\n","    # 정리\n","    out.drop(columns=['weekday','month'], inplace=True)\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oxm_SYRQ3Mzs"},"outputs":[],"source":["df = add_custom_offday_only(df, date_col='영업일자', store_col='영업장명', offday_col='휴무일', out_col='custom_offday')"]},{"cell_type":"markdown","metadata":{"id":"Og0lIdjRyLTa"},"source":["요일별 0매출 비율이 90% 이상이거나 판매 중지 기간일 시에 이상치 보간에서 제외"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Td5zBFtOxfWj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from statsmodels.tsa.seasonal import STL, seasonal_decompose\n","\n","# ─────────────────────────────────────────────────────────────\n","# 요일별 0매출 비율로 '정기 휴무 요일' 자동 판정\n","# ─────────────────────────────────────────────────────────────\n","def _detect_weekly_off_days_from_series(ts: pd.Series, min_weeks=8, tau=0.8):\n","    tmp = pd.DataFrame({\"y\": ts})\n","    tmp[\"weekday\"] = tmp.index.weekday\n","    weekly_off = set()\n","    for w in range(7):\n","        sub = tmp.loc[tmp[\"weekday\"] == w, \"y\"]\n","        n_obs = sub.notna().sum()\n","        if n_obs \u003c min_weeks:\n","            continue\n","        zero_rate = (sub.fillna(0) == 0).mean()\n","        if zero_rate \u003e= tau:\n","            weekly_off.add(w)\n","    return weekly_off\n","\n","# ─────────────────────────────────────────────────────────────\n","# 단일 (영업장명, 메뉴명) 그룹 청소 + 고립 0/이상치 선형보간\n","# ─────────────────────────────────────────────────────────────\n","def _clean_one_group(subset: pd.DataFrame,\n","                     period=7, max_interp_gap=None,  # None이면 제한 없이 보간\n","                     min_weeks=8, tau=0.8,\n","                     offday_col='휴무일', custom_off_col='custom_offday') -\u003e pd.Series | None:\n","    \"\"\"\n","    subset: 단일 (영업장명, 메뉴명) 데이터프레임\n","            반드시 포함: ['영업일자','매출수량','is_zero_sales_period']\n","            선택 포함: ['휴무일','custom_offday'] (없으면 0으로 간주)\n","    return: 청소 완료된 시계열 (DatetimeIndex, float)\n","    \"\"\"\n","    # 1) 일자 집계 \u0026 정렬\n","    g = subset.groupby('영업일자').agg(\n","        매출수량=('매출수량', 'sum'),\n","        is_zero=('is_zero_sales_period', 'max'),\n","        휴무일=(offday_col, 'max') if offday_col in subset.columns else ('영업일자', lambda x: 0),\n","        custom_offday=(custom_off_col, 'max') if custom_off_col in subset.columns else ('영업일자', lambda x: 0),\n","    ).sort_index()\n","\n","    # 2) 전체 일자 인덱스로 재색인\n","    full_idx = pd.date_range(g.index.min(), g.index.max(), freq='D')\n","    g = g.reindex(full_idx)\n","\n","    ts = g['매출수량']\n","    structural_zero = g['is_zero'].fillna(0).astype(int).eq(1)\n","    offday_mask = (g['휴무일'].fillna(0).astype(int).eq(1)) | (g['custom_offday'].fillna(0).astype(int).eq(1))\n","\n","    if len(ts) \u003c period * 2:\n","        return None  # 데이터 부족\n","\n","    # 3) 정기 휴무 요일 탐지 (판매 기록 기반)\n","    weekly_off_days = _detect_weekly_off_days_from_series(ts, min_weeks=min_weeks, tau=tau)\n","    weekday = pd.Series(ts.index.weekday, index=ts.index)\n","    weekly_off_mask = weekday.isin(weekly_off_days) \u0026 (ts.isna() | ts.eq(0))\n","\n","    # 4) 하드 0(보간 금지) 정의\n","    hard_zero_mask = structural_zero | weekly_off_mask | offday_mask\n","\n","    # 5) STL 분해용 시계열: 하드0는 NaN으로 두고, 짧은 결측만 제한 보간\n","    ts_for_decomp = ts.copy()\n","    ts_for_decomp[hard_zero_mask] = np.nan\n","    ts_for_decomp = ts_for_decomp.interpolate(\n","        method='linear',\n","        limit=max_interp_gap,  # None이면 제한 없음\n","        limit_direction='both'\n","    )\n","\n","    # 6) 분해(STL→fallback)\n","    try:\n","        stl = STL(ts_for_decomp.dropna(), period=period, robust=True)\n","        resid = stl.fit().resid.reindex(ts_for_decomp.index)\n","    except Exception:\n","        decomp = seasonal_decompose(ts_for_decomp.dropna(), model='additive', period=period)\n","        resid = decomp.resid.reindex(ts_for_decomp.index)\n","\n","    # 7) 이상치 마스크(3σ 초과), 하드0는 제외\n","    sigma = resid.std(skipna=True)\n","    outlier_mask = pd.Series(False, index=ts.index)\n","    if pd.notna(sigma) and sigma \u003e 0:\n","        outlier_mask = resid.abs() \u003e (3 * sigma)\n","        outlier_mask = outlier_mask.fillna(False) \u0026 (~hard_zero_mask)\n","\n","    # 8) '고립된 0매출' 마스크: 정기/장기/휴무가 아닌데 값이 0\n","    isolated_zero_mask = ts.eq(0) \u0026 (~hard_zero_mask)\n","\n","    # 9) 보간 대상: 고립된 0 ∪ 이상치\n","    target_mask = (isolated_zero_mask | outlier_mask)\n","\n","    # 10) 선형보간 수행\n","    ts_clean = ts.copy()\n","    guard = ts_clean[hard_zero_mask].copy()           # 하드0 값 보존(대개 0 또는 NaN)\n","    ts_clean[target_mask] = np.nan                    # 보간 대상만 NaN으로\n","    ts_final = ts_clean.interpolate(\n","        method='linear',\n","        limit=max_interp_gap,                         # None이면 전부 선형보간\n","        limit_direction='both'\n","    )\n","    # 끝단 등 남은 결측 보완 (선형보간 불가 구간)\n","    if ts_final.isna().any():\n","        ts_final = ts_final.fillna(method='ffill').fillna(method='bfill')\n","\n","    # 11) 하드0 복원(휴무 결측은 0 고정)\n","    ts_final[hard_zero_mask] = guard.fillna(0)\n","\n","    return ts_final\n","\n","# ─────────────────────────────────────────────────────────────\n","# 전체 df에 대해 그룹별 청소 수행\n","# ─────────────────────────────────────────────────────────────\n","def clean_all_series(df: pd.DataFrame,\n","                     store_col=\"영업장명\", menu_col=\"메뉴명\",\n","                     date_col=\"영업일자\", value_col=\"매출수량\",\n","                     zero_flag_col=\"is_zero_sales_period\",\n","                     offday_col=\"휴무일\", custom_off_col=\"custom_offday\",\n","                     period=7, max_interp_gap=None, min_weeks=8, tau=0.8):\n","    \"\"\"\n","    return:\n","      cleaned_series_dict: { \"영업장_메뉴\": pd.Series(DatetimeIndex) }\n","      failed_keys: 리스트 (에러/데이터부족 등으로 스킵된 키)\n","    \"\"\"\n","    cleaned_series_dict = {}\n","    failed_keys = []\n","\n","    cols = [store_col, menu_col, date_col, value_col, zero_flag_col]\n","    if offday_col in df.columns:\n","        cols.append(offday_col)\n","    if custom_off_col in df.columns:\n","        cols.append(custom_off_col)\n","\n","    d = df[cols].copy()\n","    d[date_col] = pd.to_datetime(d[date_col])\n","\n","    for (store, menu), subset in d.groupby([store_col, menu_col], sort=False):\n","        key = f\"{store}_{menu}\"\n","        try:\n","            # 열 이름 통일\n","            renamer = {\n","                date_col: '영업일자',\n","                value_col: '매출수량',\n","                zero_flag_col: 'is_zero_sales_period'\n","            }\n","            if offday_col in subset.columns:\n","                renamer[offday_col] = '휴무일'\n","            if custom_off_col in subset.columns:\n","                renamer[custom_off_col] = 'custom_offday'\n","\n","            sub = subset.rename(columns=renamer)\n","\n","            ts_clean = _clean_one_group(\n","                sub,\n","                period=period,\n","                max_interp_gap=max_interp_gap,\n","                min_weeks=min_weeks,\n","                tau=tau,\n","                offday_col='휴무일',\n","                custom_off_col='custom_offday'\n","            )\n","            if ts_clean is None:\n","                failed_keys.append((key, \"데이터 부족\"))\n","                continue\n","            cleaned_series_dict[key] = ts_clean\n","        except Exception as e:\n","            failed_keys.append((key, str(e)))\n","    return cleaned_series_dict, failed_keys\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zd80RTqjylHI"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1713288838.py:103: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  ts_final = ts_final.fillna(method='ffill').fillna(method='bfill')\n","/tmp/ipython-input-1713288838.py:103: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  ts_final = ts_final.fillna(method='ffill').fillna(method='bfill')\n","/tmp/ipython-input-1713288838.py:103: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  ts_final = ts_final.fillna(method='ffill').fillna(method='bfill')\n"]},{"name":"stdout","output_type":"stream","text":["스킵: []\n"]}],"source":["# 1) 청소 실행\n","cleaned_series_dict, failed_keys = clean_all_series(\n","    df,                           # 원본 데이터프레임\n","    store_col=\"영업장명\",\n","    menu_col=\"메뉴명\",\n","    date_col=\"영업일자\",\n","    value_col=\"매출수량\",\n","    zero_flag_col=\"is_zero_sales_period\",\n","    offday_col=\"휴무일\",\n","    custom_off_col=\"custom_offday\",\n","    period=7,\n","    max_interp_gap=5,          # 제한 없이 선형보간\n","    min_weeks=8,\n","    tau=0.85\n",")\n","print(\"스킵:\", failed_keys[:5])\n","\n","# 2) 병합 함수\n","def merge_cleaned_series(cleaned_dict: dict) -\u003e pd.DataFrame:\n","    rows = []\n","    for key, series in cleaned_dict.items():\n","        store, menu = key.split(\"_\", 1)\n","        df_tmp = pd.DataFrame({\n","            \"영업장명\": store,\n","            \"메뉴명\": menu,\n","            \"영업일자\": series.index,\n","            \"매출수량\": series.values\n","        })\n","        rows.append(df_tmp)\n","    return pd.concat(rows, ignore_index=True)\n","\n","# 3) 병합 + 후처리\n","df1 = merge_cleaned_series(cleaned_series_dict)\n","df1['매출수량'] = df1['매출수량'].clip(lower=0)  # 음수 방지\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qzS_8559W_c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["휴무일 value counts -\u003e\n","휴무일\n","0    95617\n","1     7059\n","Name: count, dtype: int64\n","custom_offday value counts -\u003e\n","custom_offday\n","0    96633\n","1     6043\n","Name: count, dtype: int64\n","is_zero_sales_period value counts -\u003e\n","is_zero_sales_period\n","0    72818\n","1    29858\n","Name: count, dtype: int64\n"]}],"source":["import pandas as pd\n","\n","def add_off_and_zero_flags(df1: pd.DataFrame,\n","                           df: pd.DataFrame,\n","                           date_col='영업일자',\n","                           shop_col='영업장명',\n","                           menu_col='메뉴명',\n","                           combined_col='영업장명_메뉴명',\n","                           cols_to_add=('휴무일','custom_offday','is_zero_sales_period'),\n","                           prefer_df1=True):\n","    \"\"\"\n","    df의 ['휴무일','custom_offday','is_zero_sales_period']를 df1에 머지하여 추가/보완합니다.\n","    - 키: (영업장명, 메뉴명, 영업일자)\n","    - df1에 기존 값이 있으면 보존하고, 결측만 df 값으로 채웁니다 (prefer_df1=True).\n","      False로 주면 df의 값을 우선 적용합니다.\n","    \"\"\"\n","    df1 = df1.copy()\n","    df  = df.copy()\n","\n","    # 0) 날짜 컬럼 형 변환\n","    df1[date_col] = pd.to_datetime(df1[date_col])\n","    df[date_col]  = pd.to_datetime(df[date_col])\n","\n","    # 1) (영업장명, 메뉴명) 확보\n","    def ensure_shop_menu_columns(d):\n","        if shop_col not in d.columns or menu_col not in d.columns:\n","            if combined_col in d.columns:\n","                sp = d[combined_col].astype(str).str.split('_', n=1, expand=True)\n","                d[shop_col] = sp[0]\n","                d[menu_col] = sp[1] if sp.shape[1] \u003e 1 else ''\n","            else:\n","                raise KeyError(\"영업장/메뉴 컬럼이 없어 병합 키를 만들 수 없습니다.\")\n","        return d\n","\n","    df1 = ensure_shop_menu_columns(df1)\n","    df  = ensure_shop_menu_columns(df)\n","\n","    # 2) 가져올 컬럼 존재 여부 체크\n","    cols_available = [c for c in cols_to_add if c in df.columns]\n","    if not cols_available:\n","        raise KeyError(f\"df에 가져올 컬럼이 없습니다: {cols_to_add}\")\n","\n","    # 3) df에서 키 중복 제거(최근/마지막 값 우선)\n","    key_cols = [shop_col, menu_col, date_col]\n","    df_pull = (df[key_cols + cols_available]\n","               .sort_values(key_cols)\n","               .drop_duplicates(subset=key_cols, keep='last'))\n","\n","    # 4) 머지\n","    suffix = \"_from_df\"\n","    merged = df1.merge(df_pull, on=key_cols, how='left',\n","                       suffixes=('', suffix))\n","\n","    # 5) 우선순위에 따라 값 결합\n","    for c in cols_available:\n","        src_col = c + suffix\n","        if src_col not in merged.columns:\n","            continue\n","\n","        # 정수/불리언 성격 컬럼은 우선 float로 결합 후 캐스팅\n","        if prefer_df1:\n","            # df1 값이 우선: df1 값이 결측이면 df 값으로 채움\n","            merged[c] = merged[c].combine_first(merged[src_col])\n","        else:\n","            # df 값이 우선: df 값이 있으면 덮어씀\n","            merged[c] = merged[src_col].combine_first(merged[c])\n","\n","        # 타입 정리(가능하면 0/1 정수로)\n","        if pd.api.types.is_bool_dtype(merged[c]):\n","            merged[c] = merged[c].astype('int8')\n","        else:\n","            # 값이 0/1 또는 결측이라면 0으로 채우고 정수화\n","            if set(pd.unique(merged[c].dropna())) \u003c= {0,1}:\n","                merged[c] = merged[c].fillna(0).astype('int8')\n","\n","        merged.drop(columns=[src_col], inplace=True)\n","\n","    return merged\n","\n","# ───────── 사용 예시 ─────────\n","df1 = add_off_and_zero_flags(\n","    df1, df,\n","    date_col='영업일자',\n","    shop_col='영업장명',\n","    menu_col='메뉴명',\n","    combined_col='영업장명_메뉴명',\n","    cols_to_add=('휴무일','custom_offday','is_zero_sales_period'),\n","    prefer_df1=True   # df1 값 보존, 빈 곳만 df로 보완\n",")\n","\n","# 적용 확인 (간단 점검)\n","for c in ['휴무일','custom_offday','is_zero_sales_period']:\n","    if c in df1.columns:\n","        print(c, \"value counts -\u003e\")\n","        print(df1[c].value_counts(dropna=False).head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EiNuGBtXzB9r"},"outputs":[],"source":["# '영업장명'과 '메뉴명' 결합\n","df1['영업장명_메뉴명'] = df1['영업장명'].astype(str) + '_' + df1['메뉴명'].astype(str)\n","df1['영업일자'] = pd.to_datetime(df1['영업일자'])  # 문자열 → datetime 변환\n","df1['year'] = df1['영업일자'].dt.year\n","df1['month'] = df1['영업일자'].dt.month\n","df1['day'] = df1['영업일자'].dt.day\n","df1['weekday'] = pd.to_datetime(df1['영업일자']).dt.weekday\n","# 2. is_weekend 생성 (금~일 = 5, 6)\n","df1['is_weekend'] = df1['weekday'].astype(int).isin([5, 6]).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ui2UpRClzKxW"},"outputs":[],"source":["import pandas as pd\n","import holidays\n","\n","# 1) 날짜 캘린더 생성\n","date_list = pd.date_range(start='2023-01-01', end='2024-06-15', freq='D')\n","\n","# 2) 한국 공휴일 객체 (연도 지정해두면 빠름/안전)\n","years = list(range(date_list.year.min(), date_list.year.max() + 1))\n","kr_holidays = holidays.KR(years=years)\n","\n","# 3) 캘린더 DF + 공휴일 플래그/전후일 플래그\n","holiday_df = pd.DataFrame({'ds': date_list})\n","holiday_df['holiday'] = holiday_df['ds'].apply(lambda x: 'holiday' if x in kr_holidays else 'non-holiday')\n","holiday_df['is_holiday'] = (holiday_df['holiday'] == 'holiday').astype('int8')\n","\n","holiday_df = holiday_df.sort_values('ds')\n","holiday_df['holiday_prev1'] = holiday_df['is_holiday'].shift(1).fillna(0).astype('int8')\n","holiday_df['holiday_next1'] = holiday_df['is_holiday'].shift(-1).fillna(0).astype('int8')\n","\n","# 4) 원본 df1에 병합\n","df1 = df1.merge(\n","    holiday_df[['ds', 'holiday', 'is_holiday', 'holiday_prev1', 'holiday_next1']],\n","    how='left', left_on='영업일자', right_on='ds'\n",")\n","\n","# 5) 정리\n","df1.drop(columns=['ds'], inplace=True)\n","# (선택) 숫자형 일관성 유지\n","df1['holiday_prev1']  = pd.to_numeric(df1['holiday_prev1'], errors='coerce').fillna(0).astype('int8')\n","df1['holiday_next1']  = pd.to_numeric(df1['holiday_next1'], errors='coerce').fillna(0).astype('int8')\n","df1['is_holiday']     = pd.to_numeric(df1['is_holiday'],  errors='coerce').fillna(0).astype('int8')\n","# 문자열 'holiday'/'non-holiday' 유지가 필요 없으면 아래 줄로 삭제 가능\n","df1.drop(columns=['holiday'], inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RGhgCgJQ0QR3"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df1"},"text/html":["\n","  \u003cdiv id=\"df-5b812d1b-6c47-4cbd-b387-1b3a2c380b35\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e영업장명\u003c/th\u003e\n","      \u003cth\u003e메뉴명\u003c/th\u003e\n","      \u003cth\u003e영업일자\u003c/th\u003e\n","      \u003cth\u003e매출수량\u003c/th\u003e\n","      \u003cth\u003e휴무일\u003c/th\u003e\n","      \u003cth\u003ecustom_offday\u003c/th\u003e\n","      \u003cth\u003eis_zero_sales_period\u003c/th\u003e\n","      \u003cth\u003e영업장명_메뉴명\u003c/th\u003e\n","      \u003cth\u003eyear\u003c/th\u003e\n","      \u003cth\u003emonth\u003c/th\u003e\n","      \u003cth\u003eday\u003c/th\u003e\n","      \u003cth\u003eweekday\u003c/th\u003e\n","      \u003cth\u003eis_weekend\u003c/th\u003e\n","      \u003cth\u003eis_holiday\u003c/th\u003e\n","      \u003cth\u003eholiday_prev1\u003c/th\u003e\n","      \u003cth\u003eholiday_next1\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ\u003c/td\u003e\n","      \u003ctd\u003e1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023-01-01\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ_1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ\u003c/td\u003e\n","      \u003ctd\u003e1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023-01-02\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ_1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ\u003c/td\u003e\n","      \u003ctd\u003e1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023-01-03\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ_1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ\u003c/td\u003e\n","      \u003ctd\u003e1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023-01-04\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ_1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ\u003c/td\u003e\n","      \u003ctd\u003e1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023-01-05\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e느티나무 셀프BBQ_1인 수저세트\u003c/td\u003e\n","      \u003ctd\u003e2023\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b812d1b-6c47-4cbd-b387-1b3a2c380b35')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-5b812d1b-6c47-4cbd-b387-1b3a2c380b35 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5b812d1b-6c47-4cbd-b387-1b3a2c380b35');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","    \u003cdiv id=\"df-c52a6546-b345-4c7b-99c6-a6795bec78ae\"\u003e\n","      \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-c52a6546-b345-4c7b-99c6-a6795bec78ae')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","      \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() =\u003e {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-c52a6546-b345-4c7b-99c6-a6795bec78ae button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["         영업장명      메뉴명       영업일자  매출수량  휴무일  custom_offday  \\\n","0  느티나무 셀프BBQ  1인 수저세트 2023-01-01   0.0    0              0   \n","1  느티나무 셀프BBQ  1인 수저세트 2023-01-02   0.0    0              1   \n","2  느티나무 셀프BBQ  1인 수저세트 2023-01-03   0.0    0              0   \n","3  느티나무 셀프BBQ  1인 수저세트 2023-01-04   0.0    0              0   \n","4  느티나무 셀프BBQ  1인 수저세트 2023-01-05   0.0    0              0   \n","\n","   is_zero_sales_period            영업장명_메뉴명  year  month  day  weekday  \\\n","0                     1  느티나무 셀프BBQ_1인 수저세트  2023      1    1        6   \n","1                     1  느티나무 셀프BBQ_1인 수저세트  2023      1    2        0   \n","2                     1  느티나무 셀프BBQ_1인 수저세트  2023      1    3        1   \n","3                     1  느티나무 셀프BBQ_1인 수저세트  2023      1    4        2   \n","4                     1  느티나무 셀프BBQ_1인 수저세트  2023      1    5        3   \n","\n","   is_weekend  is_holiday  holiday_prev1  holiday_next1  \n","0           1           1              0              0  \n","1           0           0              1              0  \n","2           0           0              0              0  \n","3           0           0              0              0  \n","4           0           0              0              0  "]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EklsXyHF1l3V"},"outputs":[{"name":"stdout","output_type":"stream","text":["📌 모든 조합에서 매출이 0인 영업일자 수: 17일\n","[Timestamp('2023-03-02 00:00:00'), Timestamp('2023-03-03 00:00:00'), Timestamp('2023-03-04 00:00:00'), Timestamp('2023-03-05 00:00:00'), Timestamp('2023-03-06 00:00:00')]\n"]}],"source":["# 각 날짜별 전체 매출 합산\n","total_sales_per_day = df1.groupby('영업일자')['매출수량'].sum().reset_index()\n","\n","# 매출수량이 0인 영업일자 필터링\n","zero_sales_dates = total_sales_per_day[total_sales_per_day['매출수량'] == 0]['영업일자']\n","\n","print(f\"📌 모든 조합에서 매출이 0인 영업일자 수: {len(zero_sales_dates)}일\")\n","print(zero_sales_dates.tolist()[:5])  # 일부 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CEp0MDa03bMu"},"outputs":[],"source":["#영업장별 매출 수량이 상위권인 메뉴 표시\n","# ➊ 업장·메뉴별 누적 매출 계산\n","menu_sales = (\n","    df1\n","    .groupby(['영업장명', '영업장명_메뉴명'])['매출수량']\n","    .sum()\n","    .reset_index()\n","    .rename(columns={'매출수량': 'total_menu_sales'})\n",")\n","\n","main_menu_flags = []\n","\n","# ➋ 업장별로 주요 메뉴 식별 (비율 0.4, 또는 최고 매출의 0.5배 미만 기준)\n","for store, grp in menu_sales.groupby('영업장명'):\n","    grp = grp.sort_values('total_menu_sales', ascending=False).reset_index(drop=True)\n","    sales = grp['total_menu_sales'].values\n","    max_sales = sales[0]\n","\n","    # consecutive 비율 변화 계산 (sales[i] / sales[i-1])\n","    ratios = sales[1:] / (sales[:-1] + 1e-6)\n","\n","    # ① 비율이 0.4 미만인 최초 위치\n","    idx_ratio = np.where(ratios \u003c 0.4)[0]\n","    cutoff_ratio = idx_ratio[0] + 1 if len(idx_ratio) \u003e 0 else len(sales)\n","\n","    # ② 최고 매출의 0.5배 미만이 되는 최초 위치\n","    idx_half = np.where(sales \u003c 0.5 * max_sales)[0]\n","    cutoff_half = idx_half[0] if len(idx_half) \u003e 0 else len(sales)\n","\n","    # 최종 컷오프는 두 기준 중 더 작은 인덱스\n","    cutoff = min(cutoff_ratio, cutoff_half)\n","\n","    main_menus = grp.loc[:cutoff-1, '영업장명_메뉴명'].tolist()\n","\n","    for menu in grp['영업장명_메뉴명']:\n","        main_menu_flags.append({\n","            '영업장명_메뉴명': menu,\n","            'is_main_menu': int(menu in main_menus)\n","        })\n","\n","main_menu_df = pd.DataFrame(main_menu_flags)\n","\n","# ➌ df1에 병합\n","df1= df1.merge(\n","    main_menu_df,\n","    on='영업장명_메뉴명',\n","    how='left'\n",")\n","\n","# ➍ NaN 처리 (없으면 0으로)\n","df1['is_main_menu'] = df1['is_main_menu'].fillna(0).astype(int)"]},{"cell_type":"markdown","metadata":{"id":"-BDZWulV5k4V"},"source":["시계열 데이터 초반에 60일 이상 연속 0 데이터일 시 신규 출시라고 가정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sX7NOasE4swK"},"outputs":[],"source":["import pandas as pd\n","\n","# 1) 메뉴별 첫 판매일\n","first_sale = (df1[df1['매출수량'] \u003e 0]\n","              .groupby('영업장명_메뉴명')['영업일자']\n","              .min()\n","              .rename('first_sale_date'))\n","\n","# 2) 메뉴별 첫 관측일\n","first_seen = (df1.groupby('영업장명_메뉴명')['영업일자']\n","                .min()\n","                .rename('first_seen_date'))\n","\n","# 3) 매장별(전체 메뉴 합) 일별 매출\n","store_daily = (df1.groupby(['영업장명','영업일자'])['매출수량']\n","                 .sum()\n","                 .reset_index()\n","                 .rename(columns={'매출수량':'store_sales'}))\n","\n","# 4) 메뉴–매장 매핑\n","menu_store = df1[['영업장명_메뉴명','영업장명']].drop_duplicates()\n","\n","# 5) 메뉴별 지표 집계\n","info = (menu_store\n","        .merge(first_sale, left_on='영업장명_메뉴명', right_index=True, how='left')\n","        .merge(first_seen, left_on='영업장명_메뉴명', right_index=True, how='left'))\n","\n","# 출시 전 매장 가동 여부(해당 매장에서 첫판매 이전에 다른 매출 \u003e 0이 있었는지)\n","def had_store_sales_before(row):\n","    if pd.isna(row['first_sale_date']):\n","        # 아예 판매가 없었던 메뉴: 신규 판단 불가\n","        return False\n","    s = store_daily[(store_daily['영업장명']==row['영업장명']) \u0026\n","                    (store_daily['영업일자'] \u003c row['first_sale_date']) \u0026\n","                    (store_daily['store_sales'] \u003e 0)]\n","    return len(s) \u003e 0\n","\n","info['store_active_before'] = info.apply(had_store_sales_before, axis=1)\n","\n","# 출시 전 공백 일수\n","info['days_idle_before'] = (info['first_sale_date'] - info['first_seen_date']).dt.days\n","\n","# 출시 후 초기 60일 동안의 비0 판매일 수\n","k_window = 60\n","k_min_nonzero = 5\n","\n","def count_nonzero_after(menu):\n","    g = df1[df1['영업장명_메뉴명']==menu].sort_values('영업일자')\n","    fs = info.loc[info['영업장명_메뉴명']==menu, 'first_sale_date'].values[0]\n","    if pd.isna(fs):\n","        return 0\n","    sub = g[(g['영업일자']\u003e=fs) \u0026 (g['영업일자']\u003cfs + pd.Timedelta(days=k_window))]\n","    return int((sub['매출수량'] \u003e 0).sum())\n","\n","nz_after = {m: count_nonzero_after(m) for m in info['영업장명_메뉴명']}\n","info['nonzero_days_60d'] = info['영업장명_메뉴명'].map(nz_after)\n","\n","# 최종: 신규 출시 추정\n","info['is_probable_launch'] = (\n","    info['first_sale_date'].notna() \u0026\n","    info['store_active_before'] \u0026\n","    (info['days_idle_before'] \u003e= 60) \u0026\n","    (info['nonzero_days_60d'] \u003e= k_min_nonzero)\n",").astype(int)\n","\n","# 결과 확인\n","launch_candidates = info[info['is_probable_launch']==1] \\\n","    .sort_values(['영업장명','first_sale_date'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uXHNo-bH5jeX"},"outputs":[],"source":["# info: (영업장명_메뉴명, 영업장명, first_sale_date, first_seen_date, store_active_before, days_idle_before, nonzero_days_60d, is_probable_launch)\n","\n","# ① df에 출시 메타 병합\n","df1 = df1.merge(\n","    info[['영업장명_메뉴명','first_sale_date','first_seen_date','is_probable_launch']],\n","    on='영업장명_메뉴명', how='left'\n",")\n","\n","# ② 출시 전/후 구분 및 경과일\n","df1['days_since_launch'] = (df1['영업일자'] - df1['first_sale_date']).dt.days\n","df1['is_prelaunch']      = df1['days_since_launch'].lt(0).astype(int)      # 출시 전(True=1)\n","df1['is_postlaunch']     = df1['days_since_launch'].ge(0).astype(int)      # 출시 후(True=1)\n","\n","# ③ 출시 직후 콜드스타트 구간(예: 60일) 표시\n","COLD_DAYS = 60\n","df1['is_coldstart_60d'] = ((df1['days_since_launch'] \u003e= 0) \u0026\n","                          (df1['days_since_launch'] \u003c COLD_DAYS)).astype(int)\n","\n","# ⑤ 출시 전 구조적 0에 대한 명확한 마스크(학습 제외용)\n","df1['structural_zero'] = ((df1['is_prelaunch'] == 1) \u0026 (df1['매출수량'] == 0)).astype(int)\n","\n","# ⑥ 판매 시작이 한 번도 없던 메뉴(NaT) 처리용 플래그\n","df1['never_sold'] = df1['first_sale_date'].isna().astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RqQ3CCvYYsF4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 102676 entries, 0 to 102675\n","Data columns (total 26 columns):\n"," #   Column                Non-Null Count   Dtype         \n","---  ------                --------------   -----         \n"," 0   영업장명                  102676 non-null  object        \n"," 1   메뉴명                   102676 non-null  object        \n"," 2   영업일자                  102676 non-null  datetime64[ns]\n"," 3   매출수량                  102676 non-null  float64       \n"," 4   휴무일                   102676 non-null  int8          \n"," 5   custom_offday         102676 non-null  int8          \n"," 6   is_zero_sales_period  102676 non-null  int64         \n"," 7   영업장명_메뉴명              102676 non-null  object        \n"," 8   year                  102676 non-null  int32         \n"," 9   month                 102676 non-null  int32         \n"," 10  day                   102676 non-null  int32         \n"," 11  weekday               102676 non-null  int32         \n"," 12  is_weekend            102676 non-null  int64         \n"," 13  is_holiday            102676 non-null  int8          \n"," 14  holiday_prev1         102676 non-null  int8          \n"," 15  holiday_next1         102676 non-null  int8          \n"," 16  is_main_menu          102676 non-null  int64         \n"," 17  first_sale_date       102676 non-null  datetime64[ns]\n"," 18  first_seen_date       102676 non-null  datetime64[ns]\n"," 19  is_probable_launch    102676 non-null  int64         \n"," 20  days_since_launch     102676 non-null  int64         \n"," 21  is_prelaunch          102676 non-null  int64         \n"," 22  is_postlaunch         102676 non-null  int64         \n"," 23  is_coldstart_60d      102676 non-null  int64         \n"," 24  structural_zero       102676 non-null  int64         \n"," 25  never_sold            102676 non-null  int64         \n","dtypes: datetime64[ns](3), float64(1), int32(4), int64(10), int8(5), object(3)\n","memory usage: 15.4+ MB\n"]}],"source":["df1.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"l9ZeDsamoxX6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def add_menu_month_features(\n","    df: pd.DataFrame,\n","    date_col=\"영업일자\",\n","    shop_col=\"영업장명\",\n","    menu_col=\"메뉴명\",\n","    combined_col=\"영업장명_메뉴명\",\n","    sales_col=\"매출수량\",\n","    # 임계/파라미터\n","    top_k=3, bottom_k=3,          # MOY 상/하위 개수\n","    good_month_quantile=0.75,     # “좋은 달” 전월 롤링 분위\n","    rolling_q_window=12,          # 분위 롤링 윈도우(개월)\n","    sharp_drop_pct=-0.40,         # 전월 vs 전전월 급락 임계(%)\n","    min_abs_drop=20,              # 급락 절대량 임계\n","    min_prev=30,                  # 전전월 최소 규모\n","    share_threshold=0.05,         # 낮은 기여 임계 (전월 누적점유율)\n","    min_total_sales=1,            # 전월까지 누적합 최소\n","    min_obs_moy=2                 # MOY 평균 산출 최소 관측수(전월 시점까지)\n","):\n","    \"\"\"\n","    ✅ 누수 방지 버전: '전월 기준(lag1)'으로만 월 지표를 만들어 일(행) 단위로 붙입니다.\n","\n","    생성 컬럼(모두 lag1, 전월 기준):\n","      - lag1_is_high_season_moy, lag1_is_low_season_moy\n","      - lag1_is_good_month_quantile, lag1_is_sharp_drop_month\n","      - lag1_is_low_share_month, lag1_month_share\n","      - lag1_monthly_sales (보조 지표: 전월 월합)\n","    \"\"\"\n","    out = df.copy()\n","    out[date_col] = pd.to_datetime(out[date_col])\n","\n","    # 키 확보\n","    if shop_col not in out.columns or menu_col not in out.columns:\n","        if combined_col in out.columns:\n","            pair = out[combined_col].astype(str).str.split('_', n=1, expand=True)\n","            out[shop_col] = pair[0]\n","            out[menu_col] = pair[1] if pair.shape[1] \u003e 1 else ''\n","        else:\n","            raise KeyError(\"영업장/메뉴 키가 없어 피처를 생성할 수 없습니다.\")\n","\n","    # 월 period\n","    if ('월_기간' not in out.columns) or (not isinstance(out['월_기간'].dtype, pd.PeriodDtype)):\n","        out['월_기간'] = out[date_col].dt.to_period('M')\n","\n","    key_pair = [shop_col, menu_col]\n","    key = key_pair + ['월_기간']\n","\n","    # ── 1) 메뉴×월 월합 ─────────────────────────────────────\n","    monthly = (\n","        out.groupby(key, as_index=False)[sales_col]\n","           .sum()\n","           .rename(columns={sales_col: 'monthly_sales'})\n","           .sort_values(key)\n","    )\n","    monthly['month']   = monthly['월_기간'].dt.month\n","    monthly['m_prev']  = monthly.groupby(key_pair)['monthly_sales'].shift(1)\n","    monthly['m_prev2'] = monthly.groupby(key_pair)['monthly_sales'].shift(2)\n","    monthly['cum_prev'] = monthly.groupby(key_pair)['monthly_sales'].cumsum().shift(1)\n","\n","    # ── 2) 전월 누적 점유율 \u0026 낮은 기여달 ─────────────────────\n","    monthly['lag1_month_share'] = (monthly['m_prev'] / monthly['cum_prev'])\n","    monthly['lag1_month_share'] = monthly['lag1_month_share'] \\\n","        .replace([np.inf, -np.inf], np.nan).fillna(0.0).astype('float32')\n","\n","    monthly['lag1_is_low_share_month'] = (\n","        (monthly['cum_prev'] \u003e= float(min_total_sales)) \u0026\n","        (monthly['lag1_month_share'] \u003c= float(share_threshold))\n","    ).astype('int8')\n","\n","    # ── 3) 전월 “좋은 달”: 전월까지 롤링 분위와 비교 ───────────\n","    monthly['q_thr_prev'] = monthly.groupby(key_pair)['monthly_sales'] \\\n","        .transform(lambda s: s.shift(1).rolling(rolling_q_window, min_periods=3)\n","                   .quantile(good_month_quantile))\n","    monthly['lag1_is_good_month_quantile'] = (\n","        (monthly['m_prev'] \u003e= monthly['q_thr_prev'])\n","    ).fillna(0).astype('int8')\n","\n","    # ── 4) 전월 급락(전월 vs 전전월) ─────────────────────────\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        pct = (monthly['m_prev'] - monthly['m_prev2']) / monthly['m_prev2']\n","    abs_change = (monthly['m_prev'] - monthly['m_prev2'])\n","    cond = monthly['m_prev2'].notna() \u0026 (monthly['m_prev2'] \u003e= min_prev)\n","    monthly['lag1_is_sharp_drop_month'] = (\n","        cond \u0026 (pct \u003c= sharp_drop_pct) \u0026 (abs_change.abs() \u003e= min_abs_drop)\n","    ).astype('int8')\n","\n","    # ── 5) 전월 MOY 시즌성(전월 시점까지의 MOY 누적평균으로 순위화) ───\n","    #   각 월(1..12)에 대해 누적합/누적건수 → 전월 시점 평균\n","    for mo in range(1, 13):\n","        mask = (monthly['month'] == mo).astype('int8')\n","        monthly[f'cum_sum_m{mo}'] = (monthly['monthly_sales'] * mask).cumsum().shift(1)\n","        monthly[f'cum_cnt_m{mo}'] = (mask).cumsum().shift(1)\n","\n","    monthly['month_prev'] = monthly['month'].shift(1)\n","\n","    def _rank_moy_row(row):\n","        means = []\n","        for mo in range(1, 13):\n","            s = row.get(f'cum_sum_m{mo}', np.nan)\n","            c = row.get(f'cum_cnt_m{mo}', np.nan)\n","            means.append(np.nan if (pd.isna(c) or c \u003c min_obs_moy) else (s / c if c else np.nan))\n","        means = np.array(means, dtype='float64')\n","        valid = ~np.isnan(means)\n","        if pd.isna(row['month_prev']) or not valid.any():\n","            return 0, 0\n","        idx_prev = int(row['month_prev']) - 1\n","        if not valid[idx_prev]:\n","            return 0, 0\n","        k_high = min(top_k, valid.sum())\n","        k_low  = min(bottom_k, valid.sum())\n","        # 상위 k\n","        vals_high = np.where(valid, means, -np.inf)\n","        top_idx   = np.argsort(vals_high)[-k_high:] if k_high \u003e 0 else np.array([], dtype=int)\n","        high_flag = int(idx_prev in top_idx)\n","        # 하위 k\n","        vals_low  = np.where(valid, means, np.inf)\n","        bot_idx   = np.argsort(vals_low)[:k_low] if k_low \u003e 0 else np.array([], dtype=int)\n","        low_flag  = int(idx_prev in bot_idx)\n","        return high_flag, low_flag\n","\n","    high_low = monthly.apply(lambda r: _rank_moy_row(r), axis=1, result_type='expand')\n","    monthly['lag1_is_high_season_moy'] = high_low.iloc[:, 0].astype('int8')\n","    monthly['lag1_is_low_season_moy']  = high_low.iloc[:, 1].astype('int8')\n","\n","    # 보조: 전월 월합\n","    monthly['lag1_monthly_sales'] = monthly['m_prev'].fillna(0).astype('float32')\n","\n","    # ── 6) 일(행) 단위로 브로드캐스트 ─────────────────────────\n","    attach = [\n","        'lag1_month_share',\n","        'lag1_is_low_share_month',\n","        'lag1_is_good_month_quantile',\n","        'lag1_is_sharp_drop_month',\n","        'lag1_is_high_season_moy',\n","        'lag1_is_low_season_moy',\n","        'lag1_monthly_sales'\n","    ]\n","    out = out.merge(monthly[key + attach], on=key, how='left')\n","\n","    # 결측/타입 마무리\n","    for c in attach:\n","        if c.endswith('month_share') or c.endswith('monthly_sales'):\n","            out[c] = out[c].fillna(0.0).astype('float32')\n","        else:\n","            out[c] = out[c].fillna(0).astype('int8')\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r8LrL4aZo0Eu"},"outputs":[],"source":["df1 = add_menu_month_features(\n","    df1,\n","    date_col=\"영업일자\",\n","    shop_col=\"영업장명\",\n","    menu_col=\"메뉴명\",\n","    sales_col=\"매출수량\",\n","    top_k=3, bottom_k=3,\n","    good_month_quantile=0.75,\n","    rolling_q_window=12,\n","    sharp_drop_pct=-0.40,\n","    min_abs_drop=20,\n","    min_prev=30,\n","    share_threshold=0.05\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MQCl8kDbaKRO"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 102676 entries, 0 to 102675\n","Data columns (total 34 columns):\n"," #   Column                       Non-Null Count   Dtype         \n","---  ------                       --------------   -----         \n"," 0   영업장명                         102676 non-null  object        \n"," 1   메뉴명                          102676 non-null  object        \n"," 2   영업일자                         102676 non-null  datetime64[ns]\n"," 3   매출수량                         102676 non-null  float64       \n"," 4   휴무일                          102676 non-null  int8          \n"," 5   custom_offday                102676 non-null  int8          \n"," 6   is_zero_sales_period         102676 non-null  int64         \n"," 7   영업장명_메뉴명                     102676 non-null  object        \n"," 8   year                         102676 non-null  int32         \n"," 9   month                        102676 non-null  int32         \n"," 10  day                          102676 non-null  int32         \n"," 11  weekday                      102676 non-null  int32         \n"," 12  is_weekend                   102676 non-null  int64         \n"," 13  is_holiday                   102676 non-null  int8          \n"," 14  holiday_prev1                102676 non-null  int8          \n"," 15  holiday_next1                102676 non-null  int8          \n"," 16  is_main_menu                 102676 non-null  int64         \n"," 17  first_sale_date              102676 non-null  datetime64[ns]\n"," 18  first_seen_date              102676 non-null  datetime64[ns]\n"," 19  is_probable_launch           102676 non-null  int64         \n"," 20  days_since_launch            102676 non-null  int64         \n"," 21  is_prelaunch                 102676 non-null  int64         \n"," 22  is_postlaunch                102676 non-null  int64         \n"," 23  is_coldstart_60d             102676 non-null  int64         \n"," 24  structural_zero              102676 non-null  int64         \n"," 25  never_sold                   102676 non-null  int64         \n"," 26  월_기간                         102676 non-null  period[M]     \n"," 27  lag1_month_share             102676 non-null  float32       \n"," 28  lag1_is_low_share_month      102676 non-null  int8          \n"," 29  lag1_is_good_month_quantile  102676 non-null  int8          \n"," 30  lag1_is_sharp_drop_month     102676 non-null  int8          \n"," 31  lag1_is_high_season_moy      102676 non-null  int8          \n"," 32  lag1_is_low_season_moy       102676 non-null  int8          \n"," 33  lag1_monthly_sales           102676 non-null  float32       \n","dtypes: datetime64[ns](3), float32(2), float64(1), int32(4), int64(10), int8(10), object(3), period[M](1)\n","memory usage: 17.4+ MB\n"]}],"source":["df1.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L9wb45urqOpz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def add_low_share_month_feature_leak_safe(\n","    df: pd.DataFrame,\n","    *,\n","    date_col: str = '영업일자',\n","    shop_col: str = '영업장명',\n","    menu_col: str = '메뉴명',\n","    combined_col: str = '영업장명_메뉴명',\n","    sales_col: str = '매출수량',\n","    period_col: str = '월_기간',\n","    share_threshold: float = 0.05,          # 임계: ≤ 5%\n","    min_total_sales: float | int = 1,       # 누적합 최소\n","    overwrite: bool = True                  # 동일 컬럼 존재 시 덮어쓸지\n",") -\u003e pd.DataFrame:\n","    \"\"\"\n","    학습 안전(누수 방지) 버전:\n","      - lag1_month_share = (전월 매출 / 전월까지의 누적합)\n","      - lag1_is_low_share_month = (lag1_month_share ≤ 임계) \u0026 (누적합 ≥ min_total_sales)\n","    일(행) 단위 DF에 월 키로 브로드캐스트합니다.\n","    \"\"\"\n","    out = df.copy()\n","    out[date_col] = pd.to_datetime(out[date_col])\n","\n","    # (영업장, 메뉴) 확보\n","    if (shop_col not in out.columns) or (menu_col not in out.columns):\n","        if combined_col in out.columns:\n","            sp = out[combined_col].astype(str).str.split('_', n=1, expand=True)\n","            out[shop_col] = sp[0]\n","            out[menu_col] = sp[1] if sp.shape[1] \u003e 1 else ''\n","        else:\n","            raise KeyError(\"영업장/메뉴 키가 없어 피처를 생성할 수 없습니다.\")\n","\n","    # 월 period\n","    if (period_col not in out.columns) or (not pd.api.types.is_period_dtype(out[period_col])):\n","        out[period_col] = out[date_col].dt.to_period('M')\n","\n","    key_pair = [shop_col, menu_col]\n","    key = key_pair + [period_col]\n","\n","    # (영업장,메뉴,월) 총매출\n","    monthly = (\n","        out.groupby(key, as_index=False)[sales_col]\n","           .sum()\n","           .rename(columns={sales_col: 'monthly_sales'})\n","           .sort_values(key)\n","    )\n","\n","    # 전월/전월까지 누적합\n","    monthly['m_prev']   = monthly.groupby(key_pair)['monthly_sales'].shift(1)\n","    monthly['cum_prev'] = monthly.groupby(key_pair)['monthly_sales'].cumsum().shift(1)\n","\n","    # 전월 점유율 \u0026 낮은 기여 플래그\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        lag_share = monthly['m_prev'] / monthly['cum_prev']\n","    monthly['lag1_month_share'] = (\n","        pd.Series(lag_share).replace([np.inf, -np.inf], np.nan).fillna(0.0).astype('float32')\n","    )\n","    monthly['lag1_is_low_share_month'] = (\n","        (monthly['cum_prev'] \u003e= float(min_total_sales)) \u0026\n","        (monthly['lag1_month_share'] \u003c= float(share_threshold))\n","    ).astype('int8')\n","\n","    # 일(행) 단위로 브로드캐스트\n","    attach = ['lag1_month_share', 'lag1_is_low_share_month']\n","    merged = out.merge(monthly[key + attach], on=key, how='left', suffixes=('', '_calc'))\n","\n","    # 덮어쓰기/결측 처리\n","    for col, dtype, fill in [('lag1_month_share', 'float32', 0.0),\n","                             ('lag1_is_low_share_month', 'int8', 0)]:\n","        src = col + '_calc'\n","        if src in merged.columns:\n","            if overwrite or col not in merged.columns:\n","                merged[col] = merged[src]\n","            else:\n","                merged[col] = merged[col].combine_first(merged[src])\n","            merged.drop(columns=[src], inplace=True)\n","        merged[col] = merged[col].fillna(fill).astype(dtype)\n","\n","    return merged\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ul2aTQOdhNlB"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-2447785421.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n","  if (period_col not in out.columns) or (not pd.api.types.is_period_dtype(out[period_col])):\n"]}],"source":["df1 = add_low_share_month_feature_leak_safe(\n","    df1,\n","    share_threshold=0.05,\n","    min_total_sales=1,\n","    overwrite=True\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ICqjHEyZf620"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 102676 entries, 0 to 102675\n","Data columns (total 34 columns):\n"," #   Column                       Non-Null Count   Dtype         \n","---  ------                       --------------   -----         \n"," 0   영업장명                         102676 non-null  object        \n"," 1   메뉴명                          102676 non-null  object        \n"," 2   영업일자                         102676 non-null  datetime64[ns]\n"," 3   매출수량                         102676 non-null  float64       \n"," 4   휴무일                          102676 non-null  int8          \n"," 5   custom_offday                102676 non-null  int8          \n"," 6   is_zero_sales_period         102676 non-null  int64         \n"," 7   영업장명_메뉴명                     102676 non-null  object        \n"," 8   year                         102676 non-null  int32         \n"," 9   month                        102676 non-null  int32         \n"," 10  day                          102676 non-null  int32         \n"," 11  weekday                      102676 non-null  int32         \n"," 12  is_weekend                   102676 non-null  int64         \n"," 13  is_holiday                   102676 non-null  int8          \n"," 14  holiday_prev1                102676 non-null  int8          \n"," 15  holiday_next1                102676 non-null  int8          \n"," 16  is_main_menu                 102676 non-null  int64         \n"," 17  first_sale_date              102676 non-null  datetime64[ns]\n"," 18  first_seen_date              102676 non-null  datetime64[ns]\n"," 19  is_probable_launch           102676 non-null  int64         \n"," 20  days_since_launch            102676 non-null  int64         \n"," 21  is_prelaunch                 102676 non-null  int64         \n"," 22  is_postlaunch                102676 non-null  int64         \n"," 23  is_coldstart_60d             102676 non-null  int64         \n"," 24  structural_zero              102676 non-null  int64         \n"," 25  never_sold                   102676 non-null  int64         \n"," 26  월_기간                         102676 non-null  period[M]     \n"," 27  lag1_month_share             102676 non-null  float32       \n"," 28  lag1_is_low_share_month      102676 non-null  int8          \n"," 29  lag1_is_good_month_quantile  102676 non-null  int8          \n"," 30  lag1_is_sharp_drop_month     102676 non-null  int8          \n"," 31  lag1_is_high_season_moy      102676 non-null  int8          \n"," 32  lag1_is_low_season_moy       102676 non-null  int8          \n"," 33  lag1_monthly_sales           102676 non-null  float32       \n","dtypes: datetime64[ns](3), float32(2), float64(1), int32(4), int64(10), int8(10), object(3), period[M](1)\n","memory usage: 17.4+ MB\n"]}],"source":["df1.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GirW1a4Z56Wq"},"outputs":[],"source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","LOOKBACK = 28\n","HORIZON  = 7\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","LR = 1e-3\n","EMBED_DIM = 8        # 메뉴 임베딩 차원\n","HIDDEN = 64\n","NUM_LAYERS = 1\n","DROPOUT = 0.1\n","\n","# ==== 1) 유틸: 손실/지표 ====\n","class SMAPE_MAE_Loss(nn.Module):\n","    def __init__(self, alpha=0.8):\n","        super().__init__()\n","        self.alpha = alpha\n","    def forward(self, pred, target):\n","        smape = torch.mean(2 * torch.abs(pred - target) / (torch.abs(pred) + torch.abs(target) + 1e-8))\n","        mae = torch.mean(torch.abs(pred - target))\n","        return self.alpha * smape + (1 - self.alpha) * mae\n","\n","@torch.no_grad()\n","def smape_mae(pred, target):\n","    smape = torch.mean(2 * torch.abs(pred - target) / (torch.abs(pred) + torch.abs(target) + 1e-8)).item()\n","    mae = torch.mean(torch.abs(pred - target)).item()\n","    return smape, mae"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3Br78G947yOj"},"outputs":[],"source":["# ==== 2) 데이터셋 생성 ====\n","class SeqDataset(Dataset):\n","    def __init__(self, X, y, menu_ids):\n","        self.X = X     # (N, LOOKBACK, F)\n","        self.y = y     # (N, HORIZON)\n","        self.menu_ids = menu_ids  # (N,)\n","    def __len__(self):\n","        return len(self.X)\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx], self.menu_ids[idx]\n","\n","def build_store_datasets(store_df: pd.DataFrame, exog_cols):\n","    \"\"\"\n","    매장 내 각 메뉴의 시계열로부터 시퀀스를 만들어\n","    (train_dataset, val_dataset, scalers, menu_id_map, feature_dim) 반환\n","    \"\"\"\n","    X_tr_list, y_tr_list, mid_tr_list = [], [], []\n","    X_va_list, y_va_list, mid_va_list = [], [], []\n","\n","    # 메뉴 ID 부여\n","    menus = store_df['메뉴명'].dropna().unique().tolist()\n","    menu2id = {m:i for i,m in enumerate(sorted(menus))}\n","    n_menus = len(menu2id)\n","\n","    # 메뉴별 스케일러(매출수량만 스케일링)\n","    scalers = {}\n","\n","    for menu, g in store_df.groupby('메뉴명'):\n","        g = g.sort_values('영업일자').copy()\n","        # 필요한 컬럼 보정\n","        g['매출수량'] = g['매출수량'].fillna(0)\n","\n","        # 검증 기준 인덱스(마지막 7일)\n","        # 시퀀스 슬라이딩 시, 타깃 구간의 끝이 split_idx를 넘으면 검증으로 보냄\n","        split_date = g['영업일자'].max() - pd.Timedelta(days=HORIZON-1)\n","        split_idx = g.index[g['영업일자'] \u003e= split_date][0]  # 마지막 7일의 시작 위치 인덱스값\n","\n","        train_mask = g.index \u003c split_idx           # 마지막 7일 시작 index 이전만\n","        scaler = MinMaxScaler().fit(g.loc[train_mask, ['매출수량']])\n","        g['scaled_sales'] = scaler.transform(g[['매출수량']])\n","        scalers[menu] = scaler\n","\n","        # 시계열 배열 구성\n","        feats = ['scaled_sales'] + exog_cols\n","        arr = g[feats].fillna(0).values.astype('float32')\n","        mid = np.full((len(g),), menu2id[menu], dtype='int64')\n","\n","        # 시퀀스 만들기\n","        # i ... i+LOOKBACK-1 -\u003e 입력, i+LOOKBACK ... i+LOOKBACK+HORIZON-1 -\u003e 타깃\n","        for i in range(len(g) - LOOKBACK - HORIZON + 1):\n","            X_seq = arr[i:i+LOOKBACK, :]\n","            y_seq = g['scaled_sales'].values[i+LOOKBACK:i+LOOKBACK+HORIZON]\n","            m_id  = mid[i]\n","\n","            # 타깃 구간의 마지막 시점\n","            target_end_pos = g.index[i+LOOKBACK+HORIZON-1]\n","            if target_end_pos \u003c split_idx:\n","                X_tr_list.append(X_seq)\n","                y_tr_list.append(y_seq)\n","                mid_tr_list.append(m_id)\n","            else:\n","                X_va_list.append(X_seq)\n","                y_va_list.append(y_seq)\n","                mid_va_list.append(m_id)\n","\n","    def to_tensor(xl):\n","        return torch.tensor(np.stack(xl)).float() if len(xl)\u003e0 else torch.empty(0)\n","\n","    X_tr = to_tensor(X_tr_list)\n","    y_tr = to_tensor(y_tr_list)\n","    X_va = to_tensor(X_va_list)\n","    y_va = to_tensor(y_va_list)\n","    mid_tr = torch.tensor(np.array(mid_tr_list), dtype=torch.long) if len(mid_tr_list)\u003e0 else torch.empty(0, dtype=torch.long)\n","    mid_va = torch.tensor(np.array(mid_va_list), dtype=torch.long) if len(mid_va_list)\u003e0 else torch.empty(0, dtype=torch.long)\n","\n","    train_ds = SeqDataset(X_tr, y_tr, mid_tr)\n","    valid_ds = SeqDataset(X_va, y_va, mid_va)\n","\n","    feature_dim = X_tr.shape[-1] if len(X_tr_list)\u003e0 else (X_va.shape[-1] if len(X_va_list)\u003e0 else len(['scaled_sales']+exog_cols))\n","    return train_ds, valid_ds, scalers, menu2id, feature_dim"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u4ozq5dp8PrW"},"outputs":[],"source":["# ==== 3) 모델 ====\n","class StoreLSTM(nn.Module):\n","    def __init__(self, n_menus, feature_dim, embed_dim=8, hidden=128, num_layers=1, dropout=0.1, horizon=7):\n","        super().__init__()\n","        self.embed = nn.Embedding(num_embeddings=max(n_menus,1), embedding_dim=embed_dim)\n","        self.lstm  = nn.LSTM(input_size=feature_dim + embed_dim,\n","                             hidden_size=hidden,\n","                             num_layers=num_layers,\n","                             batch_first=True,\n","                             dropout=dropout if num_layers\u003e1 else 0.0)\n","        self.head  = nn.Sequential(\n","            nn.Linear(hidden, hidden//2),\n","            nn.ReLU(),\n","            nn.Linear(hidden//2, horizon)\n","        )\n","    def forward(self, x, menu_id):\n","        # x: (B, L, F), menu_id: (B,)\n","        emb = self.embed(menu_id)                     # (B, E)\n","        emb = emb.unsqueeze(1).expand(-1, x.size(1), -1)  # (B, L, E)\n","        x_in = torch.cat([x, emb], dim=2)             # (B, L, F+E)\n","        out, (h, c) = self.lstm(x_in)\n","        last = out[:, -1, :]                          # (B, H)\n","        yhat = self.head(last)                        # (B, HORIZON)\n","        return yhat\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rcEw3Fdm8QKZ"},"outputs":[],"source":["# ==== 4) 학습 루프 ====\n","def train_one_store(store_name, store_df, exog_cols):\n","    print(f\"\\n[Train] 매장: {store_name}\")\n","    train_ds, valid_ds, scalers, menu2id, feature_dim = build_store_datasets(store_df, exog_cols)\n","    n_menus = len(menu2id)\n","\n","    if len(train_ds)==0 or len(valid_ds)==0:\n","        print(\"  ↳ 시퀀스가 부족하여 스킵 (train/valid 빈 데이터)\")\n","        return None\n","\n","    model = StoreLSTM(n_menus=n_menus, feature_dim=feature_dim,\n","                      embed_dim=EMBED_DIM, hidden=HIDDEN, num_layers=NUM_LAYERS,\n","                      dropout=DROPOUT, horizon=HORIZON).to(DEVICE)\n","    crit = SMAPE_MAE_Loss(alpha=0.8)\n","    opt  = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n","    valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n","\n","    best_val = np.inf\n","    best_state = None\n","\n","    for epoch in range(1, EPOCHS+1):\n","        model.train()\n","        tr_losses = []\n","        for Xb, yb, mb in train_loader:\n","            Xb = Xb.to(DEVICE)\n","            yb = yb.to(DEVICE)\n","            mb = mb.to(DEVICE)\n","            opt.zero_grad()\n","            pred = model(Xb, mb)\n","            loss = crit(pred, yb)\n","            loss.backward()\n","            opt.step()\n","            tr_losses.append(loss.item())\n","\n","        # validation\n","        model.eval()\n","        va_losses, all_smape, all_mae = [], [], []\n","        with torch.no_grad():\n","            for Xb, yb, mb in valid_loader:\n","                Xb = Xb.to(DEVICE)\n","                yb = yb.to(DEVICE)\n","                mb = mb.to(DEVICE)\n","                pred = model(Xb, mb)\n","                loss = crit(pred, yb)\n","                va_losses.append(loss.item())\n","                s, m = smape_mae(pred, yb)\n","                all_smape.append(s); all_mae.append(m)\n","\n","        tr_loss = np.mean(tr_losses) if tr_losses else np.nan\n","        va_loss = np.mean(va_losses) if va_losses else np.nan\n","        va_smape = np.mean(all_smape) if all_smape else np.nan\n","        va_mae   = np.mean(all_mae) if all_mae else np.nan\n","        print(f\"  Epoch {epoch:02d} | train {tr_loss:.4f} | valid {va_loss:.4f} | SMAPE {va_smape:.4f} | MAE {va_mae:.4f}\")\n","\n","        if va_loss \u003c best_val:\n","            best_val = va_loss\n","            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n","\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","\n","    return {\n","        \"model\": model,\n","        \"scalers\": scalers,\n","        \"menu2id\": menu2id,\n","        \"exog_cols\": exog_cols,\n","        \"feature_dim\": feature_dim,\n","        \"store\": store_name\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yRsmu8Ie8VK3"},"outputs":[],"source":["import pandas as pd\n","\n","# ==== 5) 전체 매장 학습 (누수-안전 lag 피처 사용) ====\n","def train_lstm_per_store(df1: pd.DataFrame, drop_leaky: bool = True):\n","    # 0) 필수 컬럼 체크\n","    needed = {'영업일자','영업장명','영업장명_메뉴명','메뉴명','매출수량'}\n","    missing = needed - set(df1.columns)\n","    if missing:\n","        raise ValueError(f\"다음 컬럼이 필요합니다: {missing}\")\n","\n","    df = df1.copy()\n","    df['영업일자'] = pd.to_datetime(df['영업일자'])\n","\n","    # 1) 기본 파생\n","    if 'weekday' not in df.columns:\n","        df['weekday'] = df['영업일자'].dt.weekday\n","    if 'is_weekend' not in df.columns:\n","        df['is_weekend'] = df['weekday'].isin([5,6]).astype(int)\n","    if 'month' not in df.columns:\n","        df['month'] = df['영업일자'].dt.month\n","    if '휴무일' not in df.columns:\n","        df['휴무일'] = 0\n","    if 'custom_offday' not in df.columns:\n","        df['custom_offday'] = 0\n","\n","    # 2) 원-핫: 항상 고정 차원(weekday=0..6, month=1..12)\n","    df['weekday'] = pd.Categorical(df['weekday'].astype(int), categories=list(range(7)), ordered=True)\n","    df['month']   = pd.Categorical(df['month'].astype(int),   categories=list(range(1,13)), ordered=True)\n","\n","    wd = pd.get_dummies(df['weekday'], prefix='wd', dtype='int8')\n","    m  = pd.get_dummies(df['month'],   prefix='m',  dtype='int8')\n","    # 누락된 더미가 있으면 채워 넣기(이론상 위 Categorical로 이미 모두 생성됨)\n","    for c in [f'wd_{i}' for i in range(7)]:\n","        if c not in wd.columns: wd[c] = 0\n","    for c in [f'm_{i}' for i in range(1,13)]:\n","        if c not in m.columns: m[c] = 0\n","\n","    wd = wd[[f'wd_{i}' for i in range(7)]]\n","    m  = m[[f'm_{i}'  for i in range(1,13)]]\n","\n","    df = pd.concat([df, wd, m], axis=1)\n","    wd_cols = list(wd.columns)\n","    m_cols  = list(m.columns)\n","\n","    # 3) 사용할 외생 변수(존재하는 것만 채택)\n","    #    - 누수-안전 lag1 계열만 명시\n","    lag_safe_candidates = [\n","        # 공휴일\n","        'is_holiday', 'holiday_prev1', 'holiday_next1',\n","        # 런칭/수명주기 (날짜로 결정되는 지표라 누수 아님)\n","        'is_probable_launch',\n","        # 운영 플래그\n","        'custom_offday', '휴무일',\n","        # 메뉴 중요도\n","        'is_main_menu',\n","        # 월 지표(모두 lag1만 사용)\n","        'lag1_is_high_season_moy',\n","        'lag1_is_good_month_quantile',\n","        'lag1_is_low_share_month', 'lag1_month_share',\n","        # 선택: 월합 변화의 lag1 (있을 때만)\n","        'lag1_monthly_sales', 'lag1_monthly_abs_change', 'lag1_monthly_pct_change',\n","    ]\n","\n","    # 실제 존재하는 컬럼만 채택 + 원-핫 더미 추가\n","    exog_cols = [c for c in lag_safe_candidates if c in df.columns] + wd_cols + m_cols\n","\n","    # 4) 매장별 학습\n","    trained = {}\n","    for store, g in df.groupby('영업장명', sort=False):\n","        g = g.sort_values('영업일자')\n","        # 여기서 결측이 있다면 0으로 채움(대부분 lag1_*는 생성 시 0으로 채워져 있음)\n","        X_cols = [c for c in exog_cols if c in g.columns]\n","        g[X_cols] = g[X_cols].fillna(0)\n","\n","        # train_one_store(store, g, exog_cols) 는 기존 함수 시그니처를 그대로 사용\n","        result = train_one_store(store, g, X_cols)\n","        if result is not None:\n","            trained[store] = result\n","    return trained\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YmHb_ecO82MQ"},"outputs":[],"source":["if 'holiday' in df1.columns:\n","    df1['holiday'] = (\n","        df1['holiday']\n","        .replace({'holiday': 1, 'non-holiday': 0})\n","        .fillna(0)\n","        .astype(int)\n","    )\n","trained_models = train_lstm_per_store(df1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hC5ubRR1vhdf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# ---------------------------------------------\n","# 공통 유틸: 키/날짜 보정\n","# ---------------------------------------------\n","def _ensure_keys_and_date(df, date_col='영업일자', shop_col='영업장명', menu_col='메뉴명', combined_col='영업장명_메뉴명'):\n","    out = df.copy()\n","    out[date_col] = pd.to_datetime(out[date_col])\n","    if (shop_col not in out.columns) or (menu_col not in out.columns):\n","        if combined_col in out.columns:\n","            sp = out[combined_col].astype(str).str.split('_', n=1, expand=True)\n","            out[shop_col] = sp[0]\n","            out[menu_col] = sp[1] if sp.shape[1] \u003e 1 else ''\n","        else:\n","            raise KeyError(\"훈련 DF에 ('영업장명','메뉴명') 또는 '영업장명_메뉴명'이 필요합니다.\")\n","    return out\n","\n","# ---------------------------------------------\n","# 1) first_sale_table: 출시일(첫 판매일) 표\n","#    -\u003e preprocess_test_df_for_inference(first_sale_table=...)에 사용\n","# ---------------------------------------------\n","def build_first_sale_table(train_df: pd.DataFrame,\n","                           date_col='영업일자', shop_col='영업장명', menu_col='메뉴명',\n","                           sales_col='매출수량') -\u003e pd.DataFrame:\n","    d = _ensure_keys_and_date(train_df, date_col, shop_col, menu_col)\n","    d = d.sort_values([shop_col, menu_col, date_col])\n","    # 첫 판매일(매출수량 \u003e 0)\n","    first_sale = (d[d[sales_col] \u003e 0]\n","                    .groupby([shop_col, menu_col], as_index=False)[date_col]\n","                    .min()\n","                    .rename(columns={date_col: 'first_sale_date'}))\n","    # 영업장명_메뉴명도 같이 제공(머지 유연성)\n","    first_sale['영업장명_메뉴명'] = first_sale[shop_col].astype(str) + '_' + first_sale[menu_col].astype(str)\n","    return first_sale\n","\n","# ---------------------------------------------\n","# 2) main_menu_df: 매장별 주요 메뉴 집합\n","#    (기본 규칙: 누적 매출 내림차순에서\n","#     - 연속비 0.4 미만 최초 지점까지,\n","#     - 또는 최고 매출의 0.5배 미만 최초 지점까지\n","#     중 더 엄격한 컷 사용)\n","#    -\u003e preprocess_test_df_for_inference(main_menu_df=...)에 사용\n","# ---------------------------------------------\n","def build_main_menu_df(train_df: pd.DataFrame,\n","                       date_col='영업일자', shop_col='영업장명', menu_col='메뉴명',\n","                       sales_col='매출수량',\n","                       ratio_gap=0.4, half_of_max=0.5) -\u003e pd.DataFrame:\n","    d = _ensure_keys_and_date(train_df, date_col, shop_col, menu_col)\n","    menu_sales = (d.groupby([shop_col, menu_col], as_index=False)[sales_col]\n","                    .sum()\n","                    .rename(columns={sales_col: 'total_menu_sales'}))\n","    rows = []\n","    for store, g in menu_sales.groupby(shop_col, sort=False):\n","        g = g.sort_values('total_menu_sales', ascending=False).reset_index(drop=True)\n","        sales = g['total_menu_sales'].values\n","        if len(sales) == 0:\n","            continue\n","        max_sales = sales[0]\n","        # 연속비(다음/이전)\n","        ratios = sales[1:] / (sales[:-1] + 1e-6)\n","        idx_ratio = np.where(ratios \u003c ratio_gap)[0]\n","        cutoff_ratio = idx_ratio[0] + 1 if len(idx_ratio) \u003e 0 else len(sales)\n","        # 최고 대비 0.5배 미만\n","        idx_half = np.where(sales \u003c half_of_max * max_sales)[0]\n","        cutoff_half = idx_half[0] if len(idx_half) \u003e 0 else len(sales)\n","        cutoff = min(cutoff_ratio, cutoff_half)\n","        main_menus = set(g.loc[:cutoff-1, menu_col].tolist())\n","        for _, r in g.iterrows():\n","            rows.append({\n","                '영업장명': store,\n","                '메뉴명': r[menu_col],\n","                '영업장명_메뉴명': f\"{store}_{r[menu_col]}\",\n","                'is_main_menu': int(r[menu_col] in main_menus)\n","            })\n","    out = pd.DataFrame(rows)\n","    if out.empty:\n","        return pd.DataFrame(columns=['영업장명','메뉴명','영업장명_메뉴명','is_main_menu'])\n","    out['is_main_menu'] = out['is_main_menu'].astype('int8')\n","    return out\n","\n","# ---------------------------------------------\n","# 3) off_union_mday_df: 매장별 '연속 0매출(\u003e=min_run일)' 구간의 (월,일) 합집합\n","#    -\u003e preprocess_test_df_for_inference(off_union_mday_df=...)에 사용\n","# ---------------------------------------------\n","def build_off_union_mday_df(train_df: pd.DataFrame,\n","                            date_col='영업일자', store_col='영업장명',\n","                            sales_col='매출수량', min_run=4) -\u003e pd.DataFrame:\n","    d = _ensure_keys_and_date(train_df, date_col, store_col, '메뉴명')\n","    # 매장×일자 총매출\n","    daily = (d.groupby([store_col, date_col], as_index=False)[sales_col]\n","               .sum()\n","               .rename(columns={sales_col: 'store_sales'}))\n","    rows = []\n","    for store, g in daily.groupby(store_col, sort=False):\n","        g = g.sort_values(date_col)\n","        full_idx = pd.date_range(g[date_col].min(), g[date_col].max(), freq='D')\n","        s = (g.set_index(date_col)['store_sales']\n","               .reindex(full_idx)\n","               .fillna(0.0))\n","        z = (s == 0).astype(int)\n","        run_id = (z.diff().fillna(z.iloc[0]) != 0).cumsum()\n","        tmp = (pd.DataFrame({'z': z, 'run_id': run_id})\n","                 .groupby('run_id', group_keys=False)\n","                 .apply(lambda d: pd.Series({\n","                     'flag': d['z'].iloc[0] == 1,\n","                     'start': d.index.min(),\n","                     'end': d.index.max(),\n","                     'len': len(d)\n","                 })))\n","        zero_runs = tmp[(tmp['flag']) \u0026 (tmp['len'] \u003e= min_run)]\n","        if zero_runs.empty:\n","            continue\n","        for _, r in zero_runs.iterrows():\n","            days = pd.date_range(r['start'], r['end'], freq='D')\n","            rows.append(pd.DataFrame({\n","                store_col: store,\n","                'month': days.month,\n","                'day': days.day,\n","                'is_union_offday': 1\n","            }))\n","    if rows:\n","        out = (pd.concat(rows, ignore_index=True)\n","                 .drop_duplicates([store_col, 'month', 'day']))\n","    else:\n","        out = pd.DataFrame(columns=[store_col, 'month', 'day', 'is_union_offday'])\n","    out['is_union_offday'] = out.get('is_union_offday', 0).astype('int8')\n","    return out\n","\n","# ---------------------------------------------\n","# 4) monthly_history: (영업장명, 메뉴명, 월_기간, monthly_sales)\n","#    -\u003e predict 전처리에서 lag1 월 피처 계산에 사용\n","# ---------------------------------------------\n","def build_monthly_history(train_df: pd.DataFrame,\n","                          date_col='영업일자', shop_col='영업장명',\n","                          menu_col='메뉴명', sales_col='매출수량') -\u003e pd.DataFrame:\n","    d = _ensure_keys_and_date(train_df, date_col, shop_col, menu_col)\n","    d['월_기간'] = d[date_col].dt.to_period('M')\n","    mh = (d.groupby([shop_col, menu_col, '월_기간'], as_index=False)[sales_col]\n","            .sum()\n","            .rename(columns={sales_col: 'monthly_sales'}))\n","    return mh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Cs8Bvz8Evj8h"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n"]},{"name":"stdout","output_type":"stream","text":["         영업장명          메뉴명 first_sale_date                영업장명_메뉴명\n","0  느티나무 셀프BBQ      1인 수저세트      2023-01-17      느티나무 셀프BBQ_1인 수저세트\n","1  느티나무 셀프BBQ    BBQ55(단체)      2023-01-03    느티나무 셀프BBQ_BBQ55(단체)\n","2  느티나무 셀프BBQ  대여료 30,000원      2023-01-01  느티나무 셀프BBQ_대여료 30,000원\n","is_main_menu\n","0    168\n","1     25\n","Name: count, dtype: int64\n","         영업장명  month  day  is_union_offday\n","0  느티나무 셀프BBQ      3    1                1\n","1  느티나무 셀프BBQ      3    2                1\n","2  느티나무 셀프BBQ      3    3                1\n","         영업장명      메뉴명     월_기간  monthly_sales\n","0  느티나무 셀프BBQ  1인 수저세트  2023-01           82.0\n","1  느티나무 셀프BBQ  1인 수저세트  2023-02          162.5\n","2  느티나무 셀프BBQ  1인 수저세트  2023-03           39.5\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n","/tmp/ipython-input-248179391.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda d: pd.Series({\n"]}],"source":["# 훈련 DF 지정 (예: df1 또는 train_df)\n","train_df = df1  # 훈련 구간만 포함해야 안전합니다.\n","\n","first_sale_table   = build_first_sale_table(train_df)\n","main_menu_df       = build_main_menu_df(train_df, ratio_gap=0.4, half_of_max=0.5)\n","off_union_mday_df  = build_off_union_mday_df(train_df, min_run=4)\n","monthly_history    = build_monthly_history(train_df)\n","\n","# (원하시면 간단 점검)\n","print(first_sale_table.head(3))\n","print(main_menu_df['is_main_menu'].value_counts())\n","print(off_union_mday_df.head(3))\n","print(monthly_history.head(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MCyupRL98Zqh"},"outputs":[],"source":["# ==== 6) 예측 함수(각 매장의 모든 메뉴에 대해 7일 예측) ====\n","@torch.no_grad()\n","def predict_next_7days(df1: pd.DataFrame, trained_models: dict):\n","    df = df1.copy()\n","    df['영업일자'] = pd.to_datetime(df['영업일자'])\n","    preds = []\n","\n","    for store, pack in trained_models.items():\n","        model = pack[\"model\"]\n","        model.eval()\n","        scalers = pack[\"scalers\"]\n","        menu2id = pack[\"menu2id\"]\n","        exog_cols = pack[\"exog_cols\"]\n","\n","        sdf = df[df['영업장명']==store].copy()\n","        last_date = sdf['영업일자'].max()\n","\n","        for menu, g in sdf.groupby('메뉴명'):\n","            if menu not in scalers or menu not in menu2id:\n","                continue\n","            g = g.sort_values('영업일자').copy()\n","            if len(g) \u003c LOOKBACK:\n","                continue\n","\n","            scaler = scalers[menu]\n","            g['scaled_sales'] = scaler.transform(g[['매출수량']])\n","            feats = ['scaled_sales'] + exog_cols\n","            arr = g[feats].fillna(0).values.astype('float32')\n","\n","            X_seq = torch.tensor(arr[-LOOKBACK:], dtype=torch.float32).unsqueeze(0).to(DEVICE)\n","            m_id  = torch.tensor([menu2id[menu]], dtype=torch.long).to(DEVICE)\n","            yhat_scaled = model(X_seq, m_id).cpu().numpy().ravel()\n","            # 역스케일\n","            yhat = scaler.inverse_transform(yhat_scaled.reshape(-1,1)).ravel()\n","\n","            # 예측 날짜 생성\n","            future_days = pd.date_range(last_date + pd.Timedelta(days=1), periods=HORIZON, freq='D')\n","            for d, val in zip(future_days, yhat):\n","                preds.append([store, menu, d, float(max(val, 0.0))])\n","\n","    pred_df = pd.DataFrame(preds, columns=['영업장명','메뉴명','예측일자','예측수량'])\n","    return pred_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ueH6edQvu_-j"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def preprocess_test_df_for_inference(\n","    test_df: pd.DataFrame,\n","    exog_cols,\n","    *,\n","    # ==== 월 lag1 피처 계산용(훈련 데이터로만 만든 것 권장) ====\n","    monthly_history: pd.DataFrame | None = None,   # ['영업장명','메뉴명','월_기간','monthly_sales']\n","\n","    # ==== 출시/메뉴/휴무 매핑(훈련에서 미리 만든 표 전달 권장) ====\n","    first_sale_table: pd.DataFrame | None = None,  # ['영업장명','메뉴명','first_sale_date']\n","    main_menu_df: pd.DataFrame | None = None,      # ['영업장명_메뉴명','is_main_menu'] 또는 ['영업장명','메뉴명','is_main_menu']\n","    off_union_mday_df: pd.DataFrame | None = None, # ['영업장명','month','day','is_union_offday']  (아래 helper 참조)\n","\n","    # ==== lag 판정 파라미터(훈련과 동일 유지) ====\n","    share_threshold: float = 0.05,\n","    min_total_sales: float | int = 1,\n","    sharp_drop_pct: float = -0.40,\n","    min_abs_drop: float = 20,\n","    min_prev: float = 30,\n","    good_month_quantile: float = 0.75,\n","    rolling_q_window: int = 12,\n","    top_k: int = 3,\n","    bottom_k: int = 3,\n","    min_obs_moy: int = 2,\n","):\n","    \"\"\"\n","    테스트 DF 전처리:\n","      - 키/날짜 파생 + 공휴일/전후일\n","      - wd_0..6, m_1..12 고정 원핫\n","      - 훈련 history 기반 lag1 월 피처\n","      - ✨ 출시 이후 플래그(is_probable_launch=1) 적용(= post-launch)\n","      - ✨ 매장별 '연속 0매출(\u003e=4일)' 구간의 월-일 합집합으로 휴무일=1\n","      - ✨ 휴무일==0에서만 custom_offday 규칙 적용\n","      - ✨ 훈련에서 산정한 main_menu 집합 그대로 적용\n","      - exog_cols 중 누락은 0으로 보완\n","    \"\"\"\n","    df = test_df.copy()\n","\n","    # ── 0) 키/날짜 파생 ───────────────────────────────────────────\n","    if ('영업장명' not in df.columns) or ('메뉴명' not in df.columns):\n","        if '영업장명_메뉴명' not in df.columns:\n","            raise KeyError(\"테스트 DF에 '영업장명_메뉴명' 또는 ('영업장명','메뉴명')가 필요합니다.\")\n","        sp = df['영업장명_메뉴명'].astype(str).str.split('_', n=1, expand=True)\n","        df['영업장명'] = sp[0]; df['메뉴명'] = sp[1] if sp.shape[1] \u003e 1 else ''\n","\n","    df['영업일자'] = pd.to_datetime(df['영업일자'])\n","    df['weekday']  = df['영업일자'].dt.weekday\n","    df['month']    = df['영업일자'].dt.month\n","    df['day']      = df['영업일자'].dt.day\n","    df['월_기간']    = df['영업일자'].dt.to_period('M')\n","\n","    # ── 1) 공휴일/전후일 ──────────────────────────────────────────\n","    try:\n","        import holidays as pyholidays\n","        years = list(range(df['영업일자'].dt.year.min(), df['영업일자'].dt.year.max() + 1))\n","        kr = pyholidays.KR(years=years)\n","        cal = pd.DataFrame({'영업일자': pd.date_range(df['영업일자'].min(), df['영업일자'].max(), freq='D')})\n","        cal['is_holiday'] = cal['영업일자'].dt.date.map(lambda d: 1 if d in kr else 0).astype('int8')\n","    except Exception:\n","        cal = pd.DataFrame({'영업일자': pd.date_range(df['영업일자'].min(), df['영업일자'].max(), freq='D')})\n","        fixed_days = {(1,1),(3,1),(5,5),(6,6),(8,15),(10,3),(10,9),(12,25)}\n","        cal['is_holiday'] = cal['영업일자'].map(lambda d: 1 if (d.month, d.day) in fixed_days else 0).astype('int8')\n","\n","    cal = cal.sort_values('영업일자')\n","    cal['holiday_prev1'] = cal['is_holiday'].shift(1).fillna(0).astype('int8')\n","    cal['holiday_next1'] = cal['is_holiday'].shift(-1).fillna(0).astype('int8')\n","    df = df.merge(cal, on='영업일자', how='left')\n","\n","    # ── 2) 요일/월 원핫(고정 차원) ────────────────────────────────\n","    df['weekday'] = pd.Categorical(df['weekday'].astype(int), categories=list(range(7)), ordered=True)\n","    df['month']   = pd.Categorical(df['month'].astype(int),   categories=list(range(1,13)), ordered=True)\n","    wd = pd.get_dummies(df['weekday'], prefix='wd', dtype='int8')[[f'wd_{i}' for i in range(7)]]\n","    m  = pd.get_dummies(df['month'],   prefix='m',  dtype='int8')[[f'm_{i}' for i in range(1,13)]]\n","    df = pd.concat([df, wd, m], axis=1)\n","\n","    # ── 3) lag1 월 피처(훈련 history로 계산) ───────────────────────\n","    lag_cols = [\n","        'lag1_month_share','lag1_is_low_share_month',\n","        'lag1_monthly_sales','lag1_monthly_abs_change','lag1_monthly_pct_change',\n","        'lag1_is_good_month_quantile',\n","        'lag1_is_high_season_moy',\n","    ]\n","    for c in lag_cols:\n","        if c not in df.columns:\n","            df[c] = 0  # 기본값\n","\n","    if monthly_history is not None and len(monthly_history):\n","        mh = monthly_history.copy()\n","        if '월_기간' not in mh.columns:\n","            raise KeyError(\"monthly_history에는 '월_기간'(period[M]) 컬럼이 필요합니다.\")\n","        if not isinstance(mh['월_기간'].dtype, pd.PeriodDtype):\n","            mh['월_기간'] = pd.PeriodIndex(mh['월_기간'], freq='M')\n","        for c in ['영업장명','메뉴명','월_기간','monthly_sales']:\n","            if c not in mh.columns:\n","                raise KeyError(f\"monthly_history에 '{c}' 컬럼이 필요합니다.\")\n","\n","        feats_rows = []\n","        test_months = df[['영업장명','메뉴명','월_기간']].drop_duplicates()\n","\n","        for (store, menu), g_hist in mh.groupby(['영업장명','메뉴명'], sort=False):\n","            s = g_hist.sort_values('월_기간').set_index('월_기간')['monthly_sales'].astype(float)\n","            if s.empty:\n","                continue\n","            cum = s.cumsum()\n","            s_shift = s.shift(1)\n","\n","            # MOY 누적 평균 준비\n","            month_idx = pd.Index([p.month for p in s.index], name='m')\n","            cum_sum = {mo: (s.where(month_idx==mo)).cumsum().shift(1) for mo in range(1,13)}\n","            cum_cnt = {mo: (s.where(month_idx==mo).notna().astype(int)).cumsum().shift(1) for mo in range(1,13)}\n","\n","            tms = test_months[(test_months['영업장명']==store) \u0026 (test_months['메뉴명']==menu)]['월_기간']\n","            for tm in tms:\n","                prev, prev2 = tm-1, tm-2\n","                m_prev  = float(s.get(prev, 0.0))\n","                m_prev2 = s.get(prev2, np.nan)\n","                cum_prev = float(cum.get(prev, 0.0))\n","\n","                # 점유율/low-share\n","                l_share = (m_prev / cum_prev) if cum_prev \u003e 0 else 0.0\n","                l_low   = int((cum_prev \u003e= float(min_total_sales)) and (l_share \u003c= float(share_threshold)))\n","\n","                # 전월 변화\n","                if pd.isna(m_prev2) or (float(m_prev2) == 0.0):\n","                    l_abs = float(m_prev - (0.0 if pd.isna(m_prev2) else float(m_prev2)))\n","                    l_pct = 0.0\n","                else:\n","                    l_abs = float(m_prev - float(m_prev2))\n","                    l_pct = float(l_abs / float(m_prev2))\n","\n","                # 급락\n","                l_drop = int((not pd.isna(m_prev2)) and (float(m_prev2) \u003e= float(min_prev)) and\n","                             (l_pct \u003c= float(sharp_drop_pct)) and (abs(l_abs) \u003e= float(min_abs_drop)))\n","\n","                # 좋은 달 분위\n","                past = s_shift.loc[:prev].dropna()\n","                if len(past) \u003e= max(3, rolling_q_window//2):\n","                    thr = past.tail(rolling_q_window).quantile(good_month_quantile)\n","                    l_good = int(m_prev \u003e= float(thr))\n","                else:\n","                    l_good = 0\n","\n","                # MOY 상/하위\n","                mo_prev = prev.month\n","                vals, idxs = [], []\n","                for mo in range(1,13):\n","                    cs, cc = cum_sum[mo], cum_cnt[mo]\n","                    if prev in cs.index:\n","                        ssum, scnt = cs.loc[prev], cc.loc[prev]\n","                        if pd.notna(scnt) and scnt \u003e= min_obs_moy and pd.notna(ssum):\n","                            vals.append(float(ssum/scnt)); idxs.append(mo-1)\n","                if len(vals) \u003e 0:\n","                    order = np.argsort(vals)\n","                    top_idx = np.array(idxs)[order[-min(top_k,len(vals)):]] if top_k\u003e0 else np.array([],dtype=int)\n","                    low_idx = np.array(idxs)[order[:min(bottom_k,len(vals))]] if bottom_k\u003e0 else np.array([],dtype=int)\n","                    l_high = int((mo_prev-1) in top_idx)\n","                    l_lowm = int((mo_prev-1) in low_idx)\n","                else:\n","                    l_high = 0; l_lowm = 0\n","\n","                feats_rows.append({\n","                    '영업장명': store, '메뉴명': menu, '월_기간': tm,\n","                    'lag1_month_share': np.float32(l_share),\n","                    'lag1_is_low_share_month': np.int8(l_low),\n","                    'lag1_monthly_sales': np.float32(m_prev),\n","                    'lag1_monthly_abs_change': np.float32(l_abs),\n","                    'lag1_monthly_pct_change': np.float32(l_pct),\n","                    'lag1_is_sharp_drop_month': np.int8(l_drop),\n","                    'lag1_is_good_month_quantile': np.int8(l_good),\n","                    'lag1_is_high_season_moy': np.int8(l_high),\n","                    'lag1_is_low_season_moy':  np.int8(l_lowm),\n","                })\n","\n","        if feats_rows:\n","            lag_df = pd.DataFrame(feats_rows)\n","            df = df.merge(lag_df, on=['영업장명','메뉴명','월_기간'], how='left', suffixes=('', '_calc'))\n","            for col, dtype, fill in [\n","                ('lag1_month_share','float32',0.0),\n","                ('lag1_is_low_share_month','int8',0),\n","                ('lag1_monthly_sales','float32',0.0),\n","                ('lag1_monthly_abs_change','float32',0.0),\n","                ('lag1_monthly_pct_change','float32',0.0),\n","                ('lag1_is_good_month_quantile','int8',0),\n","                ('lag1_is_high_season_moy','int8',0),\n","            ]:\n","                src = col + '_calc'\n","                if src in df.columns:\n","                    df[col] = df[src]; df.drop(columns=[src], inplace=True)\n","                df[col] = df[col].fillna(fill).astype(dtype)\n","\n","    # ── 4) 출시 이후 플래그 = is_probable_launch (요청대로) ─────────\n","    #     정의: 해당 (영업장명,메뉴명)의 first_sale_date 이후인 날짜면 1, 아니면 0\n","    if ('is_probable_launch' in exog_cols):\n","        if (first_sale_table is not None) and len(first_sale_table):\n","            fst = first_sale_table.copy()\n","            # 키 정렬\n","            if '영업장명' not in fst.columns or '메뉴명' not in fst.columns:\n","                if '영업장명_메뉴명' in fst.columns:\n","                    sp = fst['영업장명_메뉴명'].astype(str).str.split('_', n=1, expand=True)\n","                    fst['영업장명'] = sp[0]; fst['메뉴명'] = sp[1] if sp.shape[1]\u003e1 else ''\n","                else:\n","                    raise KeyError(\"first_sale_table에는 ('영업장명','메뉴명') 또는 '영업장명_메뉴명'이 필요합니다.\")\n","            if 'first_sale_date' not in fst.columns:\n","                raise KeyError(\"first_sale_table에는 'first_sale_date'가 필요합니다.\")\n","            fst['first_sale_date'] = pd.to_datetime(fst['first_sale_date'])\n","            df = df.merge(fst[['영업장명','메뉴명','first_sale_date']], on=['영업장명','메뉴명'], how='left')\n","            df['is_probable_launch'] = (df['영업일자'] \u003e= df['first_sale_date']).astype('int8').fillna(0)\n","            df.drop(columns=['first_sale_date'], inplace=True)\n","        else:\n","            # 정보 없으면 0으로\n","            if 'is_probable_launch' not in df.columns:\n","                df['is_probable_launch'] = 0\n","\n","    # ── 5) 휴무일: 매장별 '연속 0매출(\u003e=4일)' 구간의 월-일 합집합으로 설정 ─\n","    #     (훈련에서 만든 off_union_mday_df 전달 권장)\n","    if ('휴무일' in exog_cols):\n","        # 시작값(없으면 0)\n","        if '휴무일' not in df.columns:\n","            df['휴무일'] = 0\n","        if (off_union_mday_df is not None) and len(off_union_mday_df):\n","            offu = off_union_mday_df.copy()\n","            # 필요한 컬럼 체크\n","            for c in ['영업장명','month','day','is_union_offday']:\n","                if c not in offu.columns:\n","                    raise KeyError(\"off_union_mday_df에는 ['영업장명','month','day','is_union_offday']가 필요합니다.\")\n","            tmp = df[['영업장명','month','day']].merge(\n","                offu, on=['영업장명','month','day'], how='left'\n","            )['is_union_offday'].fillna(0).astype('int8')\n","            # 기존 휴무일과 OR\n","            df['휴무일'] = ((df['휴무일'].fillna(0).astype(int) \u003e 0) | (tmp == 1)).astype('int8')\n","\n","    # ── 6) custom_offday: 휴무일==0에서만 규칙 적용 ────────────────\n","    if ('custom_offday' in exog_cols):\n","        if 'custom_offday' not in df.columns:\n","            df['custom_offday'] = 0\n","        # 월, 요일 준비 (숫자형)\n","        mo = df['month'].astype(int)\n","        wd = df['weekday'].astype(int)\n","        is_op = (df['휴무일'].fillna(0).astype(int) == 0).values  # 영업 중일 때만\n","        # 포레스트릿: 4,5,9,10,11 \u0026 월요일\n","        mask = (\n","            (df['영업장명'] == '포레스트릿') \u0026\n","            (mo.isin([4,5,9,10,11])) \u0026\n","            (wd == 0) \u0026 is_op\n","        )\n","        df.loc[mask, 'custom_offday'] = 1\n","        # 연회장: 일요일\n","        mask = ((df['영업장명'] == '연회장') \u0026 (wd == 6) \u0026 is_op)\n","        df.loc[mask, 'custom_offday'] = 1\n","        # 화담숲주막/화담숲카페/라그로타/느티나무 셀프BBQ: 월요일\n","        mask = (\n","            df['영업장명'].isin(['화담숲주막','화담숲카페','라그로타','느티나무 셀프BBQ']) \u0026\n","            (wd == 0) \u0026 is_op\n","        )\n","        df.loc[mask, 'custom_offday'] = 1\n","        df['custom_offday'] = df['custom_offday'].astype('int8')\n","\n","    # ── 7) main_menu: 훈련에서의 집합 그대로 적용 ────────────────\n","    if ('is_main_menu' in exog_cols):\n","        if (main_menu_df is not None) and len(main_menu_df):\n","            mm = main_menu_df.copy()\n","            if '영업장명_메뉴명' in mm.columns and (('영업장명' not in mm.columns) or ('메뉴명' not in mm.columns)):\n","                # 그대로 merge\n","                if '영업장명_메뉴명' not in df.columns:\n","                    df['영업장명_메뉴명'] = df['영업장명'].astype(str) + '_' + df['메뉴명'].astype(str)\n","                df = df.merge(mm[['영업장명_메뉴명','is_main_menu']], on='영업장명_메뉴명', how='left')\n","            else:\n","                df = df.merge(mm[['영업장명','메뉴명','is_main_menu']], on=['영업장명','메뉴명'], how='left')\n","            df['is_main_menu'] = df['is_main_menu'].fillna(0).astype('int8')\n","        else:\n","            if 'is_main_menu' not in df.columns:\n","                df['is_main_menu'] = 0\n","\n","    # ── 8) 기타 외생변수 기본값 ───────────────────────────────────\n","    default_zero = [\n","        'is_zero_sales_period', 'is_coldstart_60d'  # 필요시 0\n","    ]\n","    for c in default_zero:\n","        if c in exog_cols and c not in df.columns:\n","            df[c] = 0\n","\n","    # object → 숫자\n","    for c in exog_cols:\n","        if c in df.columns and df[c].dtype == 'object':\n","            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n","\n","    # 최종: exog_cols 모두 보유\n","    for c in exog_cols:\n","        if c not in df.columns:\n","            df[c] = 0\n","\n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rNdTwVU7v9HV"},"outputs":[],"source":["@torch.no_grad()\n","def predict_next_7days_from_test(\n","    test_df: pd.DataFrame,\n","    trained_models: dict,\n","    *,\n","    # ✅ 훈련 구간에서 만든 (영업장명, 메뉴명, 월_기간, monthly_sales) 테이블 권장\n","    monthly_history: pd.DataFrame | None = None,\n","    # ✅ 전처리에 쓰일 매핑(훈련 데이터로 만든 표 전달)\n","    first_sale_table: pd.DataFrame | None = None,   # ['영업장명','메뉴명','first_sale_date'] 또는 '영업장명_메뉴명'\n","    main_menu_df: pd.DataFrame | None = None,       # ['영업장명','메뉴명','is_main_menu'] 또는 '영업장명_메뉴명'\n","    off_union_mday_df: pd.DataFrame | None = None,  # ['영업장명','month','day','is_union_offday']\n","\n","    # 아래 파라미터는 훈련 때와 동일값 유지 권장 (lag1 월 피처 계산용)\n","    share_threshold: float = 0.05,\n","    min_total_sales: float | int = 1,\n","    sharp_drop_pct: float = -0.40,\n","    min_abs_drop: float = 20,\n","    min_prev: float = 30,\n","    good_month_quantile: float = 0.75,\n","    rolling_q_window: int = 12,\n","    top_k: int = 3,\n","    bottom_k: int = 3,\n","):\n","    \"\"\"\n","    trained_models: train_lstm_per_store(df1) 결과(dict: store -\u003e pack)\n","      - pack: {'model','menu2id','scalers','exog_cols', ...}\n","    test_df: 이 파일(최근 28일치)만 사용해 7일 예측\n","    monthly_history: (선택) 훈련 구간의 월별 집계. 있으면 lag1 피처가 정확해집니다.\n","    first_sale_table: 출시일 테이블(출시 이후 is_probable_launch=1 적용)\n","    main_menu_df:     훈련에서 산정한 주요메뉴 집합 그대로 반영\n","    off_union_mday_df:훈련에서 찾은 '연속 0매출(\u003e=4일)' 구간의 (월,일) 합집합으로 휴무일=1 적용\n","    반환: ['영업장명','메뉴명','예측일자','예측수량']\n","    \"\"\"\n","    # 0) 모든 매장에서 사용된 exog들의 합집합 (🔒누수 가능 원천은 차단)\n","    leaky_ban = {\n","        'is_high_season_moy','is_low_season_moy',\n","        'is_good_month_quantile','is_sharp_drop_month',\n","        'is_low_share_month','month_share',\n","        'monthly_sales','monthly_abs_change','monthly_pct_change',\n","    }\n","    exog_cols_all = sorted({\n","        c for pack in trained_models.values() for c in pack['exog_cols']\n","        if c not in leaky_ban\n","    })\n","\n","    # 1) 테스트 전처리(✅ 학습과 동일 규칙, lag1 피처 계산 + 출시/휴무/커스텀오프/주요메뉴 반영)\n","    df = preprocess_test_df_for_inference(\n","        test_df,\n","        exog_cols=exog_cols_all,\n","        monthly_history=monthly_history,\n","        first_sale_table=first_sale_table,\n","        main_menu_df=main_menu_df,\n","        off_union_mday_df=off_union_mday_df,\n","        # lag1 계산 하이퍼파라미터(훈련값과 일치 권장)\n","        share_threshold=share_threshold,\n","        min_total_sales=min_total_sales,\n","        sharp_drop_pct=sharp_drop_pct,\n","        min_abs_drop=min_abs_drop,\n","        min_prev=min_prev,\n","        good_month_quantile=good_month_quantile,\n","        rolling_q_window=rolling_q_window,\n","        top_k=top_k,\n","        bottom_k=bottom_k,\n","    )\n","\n","    preds = []\n","    for store, pack in trained_models.items():\n","        sdf = df[df['영업장명'] == store].copy()\n","        if sdf.empty:\n","            continue\n","\n","        last_date = sdf['영업일자'].max()\n","        menu2id  = pack['menu2id']\n","        scalers  = pack['scalers']\n","        # 매장별 exog도 안전하게 누수 컬럼 제거 + 실제 보유 컬럼만 사용\n","        exog_cols = [c for c in pack['exog_cols'] if (c in sdf.columns) and (c not in leaky_ban)]\n","        model    = pack['model']\n","        model.eval()\n","\n","        for menu, g in sdf.groupby('메뉴명'):\n","            if (menu not in menu2id) or (menu not in scalers):\n","                # 학습 제외 메뉴일 수 있음\n","                continue\n","            g = g.sort_values('영업일자').copy()\n","            if len(g) \u003c LOOKBACK:\n","                continue\n","\n","            # 스케일 \u0026 피처 구성\n","            scaler = scalers[menu]\n","            g['scaled_sales'] = scaler.transform(g[['매출수량']])\n","            feats = ['scaled_sales'] + exog_cols\n","            arr = g[feats].fillna(0).values.astype('float32')\n","\n","            X    = torch.tensor(arr[-LOOKBACK:], dtype=torch.float32).unsqueeze(0).to(DEVICE)\n","            m_id = torch.tensor([menu2id[menu]], dtype=torch.long).to(DEVICE)\n","\n","            yhat_scaled = model(X, m_id).cpu().numpy().ravel()\n","            yhat = scaler.inverse_transform(yhat_scaled.reshape(-1, 1)).ravel()\n","\n","            future_days = pd.date_range(last_date + pd.Timedelta(days=1), periods=HORIZON, freq='D')\n","            for d, val in zip(future_days, yhat):\n","                preds.append([store, menu, d, float(max(val, 0.0))])\n","\n","    pred_df = pd.DataFrame(preds, columns=['영업장명','메뉴명','예측일자','예측수량'])\n","    return pred_df\n"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14614,"status":"ok","timestamp":1755251571557,"user":{"displayName":"Sumin Kim","userId":"08128588576306778232"},"user_tz":-540},"id":"M4dc2BaO_xPs","outputId":"e74d6943-069c-4627-abda-7a2e98eb14a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["         영업장명      메뉴명       예측일자      예측수량       source\n","0  느티나무 셀프BBQ  1인 수저세트 2024-07-14  5.726124  TEST_00.csv\n","1  느티나무 셀프BBQ  1인 수저세트 2024-07-15  4.982970  TEST_00.csv\n","2  느티나무 셀프BBQ  1인 수저세트 2024-07-16  2.672959  TEST_00.csv\n","3  느티나무 셀프BBQ  1인 수저세트 2024-07-17  3.315212  TEST_00.csv\n","4  느티나무 셀프BBQ  1인 수저세트 2024-07-18  3.541336  TEST_00.csv\n"]}],"source":["all_preds = []\n","for path in sorted(glob.glob('/content/drive/MyDrive/Colab Notebooks/LGaimers/해커톤/test/TEST_*.csv')):\n","    test_df = pd.read_csv(path)\n","    pred_df = predict_next_7days_from_test(\n","        test_df,\n","        trained_models,\n","        monthly_history=monthly_history,     # 권장\n","        first_sale_table=first_sale_table,   # ✅ 추가\n","        main_menu_df=main_menu_df,           # ✅ 추가\n","        off_union_mday_df=off_union_mday_df, # ✅ 추가\n","        share_threshold=0.05, min_total_sales=1,\n","        sharp_drop_pct=-0.40, min_abs_drop=20, min_prev=30,\n","        good_month_quantile=0.75, rolling_q_window=12,\n","        top_k=3, bottom_k=3\n","    )\n","    pred_df['source'] = os.path.basename(path)  # (선택) 추적용\n","    all_preds.append(pred_df)\n","\n","full_pred_df = pd.concat(all_preds, ignore_index=True)\n","print(full_pred_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"g7RljmALHGbi"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","def convert_predictions_to_submission_flexible(\n","    pred_df: pd.DataFrame,\n","    template_csv_path: str,\n","    output_csv_path: str,\n","    round_to_int: bool = True,\n","    horizon: int = 7\n",") -\u003e pd.DataFrame:\n","    sub = pd.read_csv(template_csv_path, dtype=str).copy()\n","    if '영업일자' not in sub.columns:\n","        raise ValueError(\"템플릿에 '영업일자' 열이 없습니다.\")\n","    target_cols = [c for c in sub.columns if c != '영업일자']\n","    id_values = sub['영업일자'].astype(str)\n","    id_mode = id_values.str.match(r'^TEST_\\d+\\+\\d+일$').all()\n","\n","    pred = pred_df.copy()\n","    if '영업장명_메뉴명' not in pred.columns:\n","        pred['영업장명_메뉴명'] = pred['영업장명'].astype(str) + '_' + pred['메뉴명'].astype(str)\n","\n","    if id_mode:\n","        if 'source' not in pred.columns:\n","            raise ValueError(\"ID 모드 변환에는 pred_df에 'source' 컬럼이 필요합니다.\")\n","\n","        def _prefix_from_source(s):\n","            m = re.search(r'(TEST_\\d+)', str(s))\n","            return m.group(1) if m else None\n","\n","        pred['prefix'] = pred['source'].map(_prefix_from_source)\n","        pred = pred.sort_values(['prefix','영업장명_메뉴명','예측일자'])\n","        pred['일오프셋'] = pred.groupby(['prefix','영업장명_메뉴명']).cumcount() + 1\n","        pred = pred[pred['일오프셋'].between(1, horizon)]\n","        pred['row_id'] = pred['prefix'] + '+' + pred['일오프셋'].astype(str) + '일'\n","\n","        pivot = pred.pivot_table(index='row_id',\n","                                 columns='영업장명_메뉴명',\n","                                 values='예측수량',\n","                                 aggfunc='sum').reindex(columns=target_cols)\n","\n","        # 🔧 핵심: 키로 병합\n","        out = sub[['영업일자']].merge(pivot, left_on='영업일자', right_index=True, how='left')\n","\n","    else:\n","        # 날짜 템플릿\n","        sub['_dt'] = pd.to_datetime(sub['영업일자'], errors='coerce', format='%Y-%m-%d')\n","        if sub['_dt'].isna().any():\n","            sub['_dt'] = pd.to_datetime(sub['영업일자'], errors='coerce')\n","        if sub['_dt'].isna().any():\n","            bad = sub['영업일자'][sub['_dt'].isna()].unique()[:5]\n","            raise ValueError(f\"템플릿 날짜 파싱 실패. 예: {bad}\")\n","\n","        pred['예측일자'] = pd.to_datetime(pred['예측일자'])\n","        pivot = pred.pivot_table(index='예측일자',\n","                                 columns='영업장명_메뉴명',\n","                                 values='예측수량',\n","                                 aggfunc='sum').reindex(columns=target_cols)\n","\n","        # 🔧 핵심: 날짜 키로 병합\n","        out = sub[['영업일자','_dt']].merge(pivot, left_on='_dt', right_index=True, how='left').drop(columns=['_dt'])\n","\n","    # 후처리\n","    for c in target_cols:\n","        out[c] = pd.to_numeric(out[c], errors='coerce').fillna(0)\n","    out[target_cols] = out[target_cols].clip(lower=0)\n","    if round_to_int:\n","        out[target_cols] = out[target_cols].round().astype(int)\n","\n","    # 최종 열 순서 정리\n","    out = out[['영업일자'] + target_cols]\n","    out.to_csv(output_csv_path, index=False)\n","    print(f\"✅ 저장 완료: {output_csv_path}\")\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WvESGt-AAbXb"},"outputs":[],"source":["converted = convert_predictions_to_submission_flexible(\n","    pred_df=full_pred_df,\n","    template_csv_path='/content/drive/MyDrive/Colab Notebooks/LGaimers/해커톤/sample_submission.csv',\n","    output_csv_path='/content/drive/MyDrive/Colab Notebooks/LGaimers/해커톤/train/submission_1.csv',\n","    round_to_int=True\n",")\n","converted.to_csv(\n","    '/content/drive/MyDrive/Colab Notebooks/LGaimers/해커톤/train/submission_1_utf8sig.csv',\n","    index=False, encoding='utf-8-sig'\n",")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}